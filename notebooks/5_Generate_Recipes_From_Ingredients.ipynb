{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Generate_Recipes_From_Ingredients.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPARfK5TDZ6hLFVRpox/955",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb38e41245ca408582655db2f6b6a25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c66e532bc5bf46908a07c0b77e428000",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec0cf9336d8747749167f3bb665cbbc2",
              "IPY_MODEL_72105e8c71ad41e1858c85b7200ca610",
              "IPY_MODEL_b6b37d324a4f433d8ec922eb39c7400e"
            ]
          }
        },
        "c66e532bc5bf46908a07c0b77e428000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec0cf9336d8747749167f3bb665cbbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a144cd1cf7114244a84802375d3d3339",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2679bd9d347c49508c668845c5ef9c8f"
          }
        },
        "72105e8c71ad41e1858c85b7200ca610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e57dd2c110b4da2811d3d7256e6d67f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 762,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 762,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fd03fcfd7ba460e8432bb3d0e5ed174"
          }
        },
        "b6b37d324a4f433d8ec922eb39c7400e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b81a0733df494a93a333ae5a5e658d20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 762/762 [00:00&lt;00:00, 25.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c132037f1c0a49b599dd6d78eae1d912"
          }
        },
        "a144cd1cf7114244a84802375d3d3339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2679bd9d347c49508c668845c5ef9c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e57dd2c110b4da2811d3d7256e6d67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fd03fcfd7ba460e8432bb3d0e5ed174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b81a0733df494a93a333ae5a5e658d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c132037f1c0a49b599dd6d78eae1d912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf8a4105e0454fbda4323adef4be595d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3fde3bc2c98045a1a64037cd9740bdc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_893493ca449449f9b0d325de46ddb919",
              "IPY_MODEL_8967a5b5e3d24dadbb2f4b22a6ce2560",
              "IPY_MODEL_bb132631892a49c488e811dfa00b042a"
            ]
          }
        },
        "3fde3bc2c98045a1a64037cd9740bdc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "893493ca449449f9b0d325de46ddb919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_deae829ac9954e85a8069bc4e9ce7fec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93fa232c420d4a4cab005d2301c10728"
          }
        },
        "8967a5b5e3d24dadbb2f4b22a6ce2560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e49527d2782408da6b02b10638f4fdb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14cfa5c0afd7427683ef3f8ccfaca398"
          }
        },
        "bb132631892a49c488e811dfa00b042a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f4af12166a54ced93bbf24a2f7e52cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 3.07MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c146a9f81764959b4fe353e96002182"
          }
        },
        "deae829ac9954e85a8069bc4e9ce7fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93fa232c420d4a4cab005d2301c10728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e49527d2782408da6b02b10638f4fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14cfa5c0afd7427683ef3f8ccfaca398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f4af12166a54ced93bbf24a2f7e52cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c146a9f81764959b4fe353e96002182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf649ab03cfc4040b4a08c0e5bc499af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95e293680fd740508cc7ba3e68977578",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cddecd3c46144e7eb4903f6a502fd4e6",
              "IPY_MODEL_81a1b7626f0b4252ae58d78e109c5384",
              "IPY_MODEL_a673f598919541c58316ab698b8c3e3c"
            ]
          }
        },
        "95e293680fd740508cc7ba3e68977578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cddecd3c46144e7eb4903f6a502fd4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_873eba68a383411f95f8e5b7850c3532",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fe11f9b7621468fb7cc91d3e971f866"
          }
        },
        "81a1b7626f0b4252ae58d78e109c5384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_54a006b6cbfb4b8ab36a383629612c1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be48dcd0dc344940b9de7d347fc11fe9"
          }
        },
        "a673f598919541c58316ab698b8c3e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41cb66e16d7245e99bda5e0dee4690d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 446k/446k [00:00&lt;00:00, 927kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7a79662a8b04a3aaf0473fc115fa235"
          }
        },
        "873eba68a383411f95f8e5b7850c3532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fe11f9b7621468fb7cc91d3e971f866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54a006b6cbfb4b8ab36a383629612c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be48dcd0dc344940b9de7d347fc11fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41cb66e16d7245e99bda5e0dee4690d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7a79662a8b04a3aaf0473fc115fa235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cb20e8766b940c7a31c43de9c7fd464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_806b89bec37549f59bf13cb052f77cbc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1a631d3797f4c8ba720c5d57f00a0c3",
              "IPY_MODEL_42c27d3d918a4ebba3e894b26edc2a77",
              "IPY_MODEL_33ae6e60c1c04c918e0ca3c49b0e6544"
            ]
          }
        },
        "806b89bec37549f59bf13cb052f77cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1a631d3797f4c8ba720c5d57f00a0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2cff4ab1d144e83b0981c793d4932da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50db32c463214f0ebcacf2bae715f6e1"
          }
        },
        "42c27d3d918a4ebba3e894b26edc2a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b037a798ca3452fa739df8efde597f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d472a5462eec4ad6b42be2dd7c0ebdce"
          }
        },
        "33ae6e60c1c04c918e0ca3c49b0e6544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33140b26af714794888add312625335b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 2.77MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_def429af9eb940b5bd940ea3901aefbb"
          }
        },
        "d2cff4ab1d144e83b0981c793d4932da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50db32c463214f0ebcacf2bae715f6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b037a798ca3452fa739df8efde597f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d472a5462eec4ad6b42be2dd7c0ebdce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33140b26af714794888add312625335b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "def429af9eb940b5bd940ea3901aefbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d9e326638444018aa1891b37ad19027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27c379587bd24b7a87419e8c2014e728",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f5eeb76ef7c4c868e11aec8d2a15c10",
              "IPY_MODEL_705d0c3f78714291a18781ae0b4ff138",
              "IPY_MODEL_793b8455e01446f2ba1ae462918faec9"
            ]
          }
        },
        "27c379587bd24b7a87419e8c2014e728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f5eeb76ef7c4c868e11aec8d2a15c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0ff96889ae924b13855f099e07ffdca4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a9fffddc1cd40109329c4ec329cb709"
          }
        },
        "705d0c3f78714291a18781ae0b4ff138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_661d5b3b0a24457dbd6077ba6e3a51ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 352833716,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 352833716,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a430d52edf6a4ac983a99fc3f9e4fde6"
          }
        },
        "793b8455e01446f2ba1ae462918faec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6bac28b88bc44719eeba62ff594cf20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 336M/336M [00:08&lt;00:00, 43.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac4726eace9f4f8d862ba3ffda8b1bbb"
          }
        },
        "0ff96889ae924b13855f099e07ffdca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a9fffddc1cd40109329c4ec329cb709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "661d5b3b0a24457dbd6077ba6e3a51ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a430d52edf6a4ac983a99fc3f9e4fde6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6bac28b88bc44719eeba62ff594cf20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac4726eace9f4f8d862ba3ffda8b1bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gborn/Knowledge-Based-Recommendation-of-Food-Ingredients/blob/main/notebooks/5_Generate_Recipes_From_Ingredients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 5: Generate Recipe from a list of Ingredients\n",
        "\n",
        "<img src=\"https://images.unsplash.com/photo-1518856853833-e405baf4646d?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=870&q=80\" width=80% height=300px/> <br>\n",
        "Image by [@qqq_saharok](https://unsplash.com/@qqq_saharok)\n",
        "\n",
        "\n",
        "### Project Breakdown\n",
        "    1  Exploratory Data Analysis and Preprocessing\n",
        "    2: Build Word Embeddings using Word2Vec, FastText\n",
        "    3: Recommend Recipes based on ingredients\n",
        "    4: Build and Visualize Interactive Knowledge Graph of Ingredients\n",
        "    5: Generate Recipes from a list of Ingredients"
      ],
      "metadata": {
        "id": "7QErasliYSMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement:\n",
        "Given a list of ingredients, we want to generate recipes that could utilize those ingredients. This would be helpful as an add-on for a smart refrigerator where the refrigerator can scan currently stored food items and suggest recipes. This can also be helpful for Chefs who want to try out new recipes from existing ingredients."
      ],
      "metadata": {
        "id": "JOVSga7da9W1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WGMwfqGCVY7E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we download recipes dataset that was preprocessed in previous notebook (Notebook 1)\n",
        "!mkdir -p data\n",
        "!gdown --id 1--jDaRFt13BqJHGd9EPR2KmsbvWSpt-t -O data/recipes.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjuatPiDXKdB",
        "outputId": "06f7e9aa-6b50-460a-a531-4125dce7f04c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--jDaRFt13BqJHGd9EPR2KmsbvWSpt-t\n",
            "To: /content/data/recipes.pkl\n",
            "100% 185M/185M [00:00<00:00, 202MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read recipes data into dataframe\n",
        "recipes = pd.read_pickle('data/recipes.pkl')\n",
        "recipes.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "-wL5j9P-fw9S",
        "outputId": "38f462eb-9a1e-4bcb-8153-050c6f43272d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-384678a4-c319-47e7-bb59-3342febb6b96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>instructions</th>\n",
              "      <th>instructions_len</th>\n",
              "      <th>ingredients_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>Slow Cooker Chicken and Dumplings</td>\n",
              "      <td>[4 skinless, boneless chicken breast halves , ...</td>\n",
              "      <td>Place the chicken, butter, soup, and onion in ...</td>\n",
              "      <td>53</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>Awesome Slow Cooker Pot Roast</td>\n",
              "      <td>[2 (10.75 ounce) cans condensed cream of mushr...</td>\n",
              "      <td>In a slow cooker, mix cream of mushroom soup, ...</td>\n",
              "      <td>44</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ar</td>\n",
              "      <td>Brown Sugar Meatloaf</td>\n",
              "      <td>[1/2 cup packed brown sugar , 1/2 cup ketchup ...</td>\n",
              "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
              "      <td>67</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ar</td>\n",
              "      <td>Best Chocolate Chip Cookies</td>\n",
              "      <td>[1 cup butter, softened , 1 cup white sugar , ...</td>\n",
              "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
              "      <td>74</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar</td>\n",
              "      <td>Homemade Mac and Cheese Casserole</td>\n",
              "      <td>[8 ounces whole wheat rotini pasta , 3 cups fr...</td>\n",
              "      <td>Preheat oven to 350 degrees F. Line a 2-quart ...</td>\n",
              "      <td>175</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-384678a4-c319-47e7-bb59-3342febb6b96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-384678a4-c319-47e7-bb59-3342febb6b96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-384678a4-c319-47e7-bb59-3342febb6b96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  source  ... ingredients_count\n",
              "0     ar  ...                 6\n",
              "1     ar  ...                 5\n",
              "2     ar  ...                11\n",
              "3     ar  ...                12\n",
              "4     ar  ...                14\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install parse-ingredients > /dev/null\n",
        "from parse_ingredients import parse_ingredient\n",
        "\n",
        "@np.vectorize\n",
        "def find_items_in_ingredients(ingredients):\n",
        "    items = []\n",
        "    try:\n",
        "        items = [parse_ingredient(ingredient).name for ingredient in ingredients if parse_ingredient(ingredient).name]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if items:\n",
        "        return ' '.join(items)"
      ],
      "metadata": {
        "id": "_fE65Jxxi6yW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_items_in_ingredients(recipes.ingredients.iloc[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta4q_WS4jeSk",
        "outputId": "b20946c5-e50c-402b-a38d-70b4c575ee1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1 / 2 c u p b u t t e r m e l t e d', '2 e g g s b e a t e n',\n",
              "       '1 ( 8 . 5 o u n c e ) p a c k a g e d r y c o r n b r e a d m i x',\n",
              "       '1 ( 1 5 o u n c e ) c a n w h o l e k e r n e l c o r n d r a i n e d',\n",
              "       '1 ( 1 4 . 7 5 o u n c e ) c a n c r e a m e d c o r n',\n",
              "       '1 c u p s o u r c r e a m', 'None'], dtype='<U69')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipes['items'] = find_items_in_ingredients(recipes.ingredients)\n",
        "recipes['items']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFculpB7ju8h",
        "outputId": "a628c7ea-7095-4b78-8402-0df2522f0ed9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         skinless butter cans condensed cream of chicke...\n",
              "1         cans condensed cream of mushroom soup package ...\n",
              "2         packed brown sugar ketchup lean ground beef mi...\n",
              "3         butter white sugar packed brown sugar eggs van...\n",
              "4         whole wheat rotini pasta fresh broccoli floret...\n",
              "                                ...                        \n",
              "124642    ears fresh corn heads Belgian endive olive oil...\n",
              "124643    large plum tomatoes Salt and sugar zucchini sa...\n",
              "124644    olive oil unsalted butter medium cloves garlic...\n",
              "124645    butter bittersweet chocolate whole eggs egg yo...\n",
              "124646    cans restaurant-style condensed crab bisque (r...\n",
              "Name: items, Length: 124647, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gob2dhiohWfL",
        "outputId": "7508adf9-68f5-44af-91e8-577dda98fcc6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124647, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n"
      ],
      "metadata": {
        "id": "Bi4cTx_ff6KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For training, we will consider Recipes with at least three ingredients, \n",
        "# and having enough instructions, say 10\n",
        "\n",
        "recipes = recipes.loc[(recipes.ingredients_count >= 3) & (recipes.instructions_len >= 10)]\n",
        "recipes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQVeZ9uIf3xU",
        "outputId": "8c60cef3-e9e2-4bac-a6a7-e5438dc1dc5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121780, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CHfdXWpXi5FA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jF08aU0Znmvb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will combine ingredients and instructions together for training\n",
        "# 🥕Ingredients: \\n 📝Instructions: \\n  SPECIAL_TOKEN\n",
        "\n",
        "START_TOKEN = '<|startoftext|>'\n",
        "END_TOKEN = '<|endoftext|>'\n",
        "\n",
        "recipes['combined'] =  recipes['items'] + '\\n' + \\\n",
        "                      '\\n' + '🥕Ingredients: \\n ' + recipes.ingredients.str.join(' \\n ') + \\\n",
        "                      '\\n' + '📝Instructions: \\n' + recipes.instructions + ' ' + END_TOKEN\n",
        "\n",
        "recipes['combined'].iloc[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "RRr9K5quhUwO",
        "outputId": "79aa475a-2afe-45b9-a2e2-1096b2518a7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'butter eggs package dry corn bread mix can whole kernel corn can creamed corn sour cream\\n\\n🥕Ingredients: \\n 1/2 cup butter, melted  \\n 2 eggs, beaten  \\n 1 (8.5 ounce) package dry corn bread mix  \\n 1 (15 ounce) can whole kernel corn, drained  \\n 1 (14.75 ounce) can creamed corn  \\n 1 cup sour cream  \\n \\n📝Instructions: \\nPreheat oven to 350 degrees F (175 degrees C), and lightly grease a 9x9 inch baking dish.\\nIn a medium bowl, combine butter, eggs, corn bread mix, whole and creamed corn and sour cream. Spoon mixture into prepared dish.\\nBake for 45 minutes in the preheated oven, or until the top is golden brown.\\n <|endoftext|>'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(recipes['combined'].iloc[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QSeXhVJqf4L",
        "outputId": "7f7df4ee-ecb6-44cd-ebd3-d2bfa426b2db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "butter eggs package dry corn bread mix can whole kernel corn can creamed corn sour cream\n",
            "\n",
            "🥕Ingredients: \n",
            " 1/2 cup butter, melted  \n",
            " 2 eggs, beaten  \n",
            " 1 (8.5 ounce) package dry corn bread mix  \n",
            " 1 (15 ounce) can whole kernel corn, drained  \n",
            " 1 (14.75 ounce) can creamed corn  \n",
            " 1 cup sour cream  \n",
            " \n",
            "📝Instructions: \n",
            "Preheat oven to 350 degrees F (175 degrees C), and lightly grease a 9x9 inch baking dish.\n",
            "In a medium bowl, combine butter, eggs, corn bread mix, whole and creamed corn and sour cream. Spoon mixture into prepared dish.\n",
            "Bake for 45 minutes in the preheated oven, or until the top is golden brown.\n",
            " <|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipes.ingredients.iloc[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNIrIctIkQtF",
        "outputId": "9f33cdc7-224d-48ab-cb24-7528f9c7a588"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1/2 cup butter, melted ',\n",
              " '2 eggs, beaten ',\n",
              " '1 (8.5 ounce) package dry corn bread mix ',\n",
              " '1 (15 ounce) can whole kernel corn, drained ',\n",
              " '1 (14.75 ounce) can creamed corn ',\n",
              " '1 cup sour cream ',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipes.instructions.iloc[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "KX8tmGi3k43N",
        "outputId": "fbc580e6-1945-4b5a-c56a-19853141edd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Preheat oven to 350 degrees F (175 degrees C), and lightly grease a 9x9 inch baking dish.\\nIn a medium bowl, combine butter, eggs, corn bread mix, whole and creamed corn and sour cream. Spoon mixture into prepared dish.\\nBake for 45 minutes in the preheated oven, or until the top is golden brown.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save data\n",
        "recipes.to_pickle('data/recipes_preprocessed.pkl')"
      ],
      "metadata": {
        "id": "WT6vvtD_pxgr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "5sV9CIOSrM1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use first 120000 data as train, and rest as test\n",
        "\n",
        "recipes_train = recipes[:120000].combined.values\n",
        "recipes_val = recipes[120000:].combined.values\n",
        "\n",
        "# save train, test splits\n",
        "# we will save data as one large text(instead of list), because that's the format GPT expects\n",
        "with open('data/train.txt', 'w') as f:\n",
        "    f.write('\\n'.join(recipes_train))\n",
        "\n",
        "with open('data/test.txt', 'w') as f:\n",
        "    f.write('\\n'.join(recipes_val))"
      ],
      "metadata": {
        "id": "cMWl3eCYrKzz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning pretrained GPT-2 Model"
      ],
      "metadata": {
        "id": "FGbfJqzltB9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use transformers library from HuggingFace.\n",
        "# They make accessible  high end Neural ends trained on incredible amount of resources, and huge amount of data,\n",
        "# that is not feasible for average person to train on.\n",
        "\n",
        "!pip install transformers > /dev/null\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# we will be using distilled version of GPT-2.\n",
        "# Distillation involves a teacher - student framework of training.\n",
        "# inputs, labels -> train a huge_model -> predictions\n",
        "# In distillation process, inputs, huge_model predictions -> train a smaller model\n",
        "# this way smaller model(student) can also learn patterns that are not represented in labels,\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
        "model = AutoModelForCausalLM.from_pretrained('distilgpt2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "bb38e41245ca408582655db2f6b6a25a",
            "c66e532bc5bf46908a07c0b77e428000",
            "ec0cf9336d8747749167f3bb665cbbc2",
            "72105e8c71ad41e1858c85b7200ca610",
            "b6b37d324a4f433d8ec922eb39c7400e",
            "a144cd1cf7114244a84802375d3d3339",
            "2679bd9d347c49508c668845c5ef9c8f",
            "2e57dd2c110b4da2811d3d7256e6d67f",
            "2fd03fcfd7ba460e8432bb3d0e5ed174",
            "b81a0733df494a93a333ae5a5e658d20",
            "c132037f1c0a49b599dd6d78eae1d912",
            "bf8a4105e0454fbda4323adef4be595d",
            "3fde3bc2c98045a1a64037cd9740bdc2",
            "893493ca449449f9b0d325de46ddb919",
            "8967a5b5e3d24dadbb2f4b22a6ce2560",
            "bb132631892a49c488e811dfa00b042a",
            "deae829ac9954e85a8069bc4e9ce7fec",
            "93fa232c420d4a4cab005d2301c10728",
            "2e49527d2782408da6b02b10638f4fdb",
            "14cfa5c0afd7427683ef3f8ccfaca398",
            "0f4af12166a54ced93bbf24a2f7e52cf",
            "6c146a9f81764959b4fe353e96002182",
            "cf649ab03cfc4040b4a08c0e5bc499af",
            "95e293680fd740508cc7ba3e68977578",
            "cddecd3c46144e7eb4903f6a502fd4e6",
            "81a1b7626f0b4252ae58d78e109c5384",
            "a673f598919541c58316ab698b8c3e3c",
            "873eba68a383411f95f8e5b7850c3532",
            "7fe11f9b7621468fb7cc91d3e971f866",
            "54a006b6cbfb4b8ab36a383629612c1d",
            "be48dcd0dc344940b9de7d347fc11fe9",
            "41cb66e16d7245e99bda5e0dee4690d2",
            "a7a79662a8b04a3aaf0473fc115fa235",
            "2cb20e8766b940c7a31c43de9c7fd464",
            "806b89bec37549f59bf13cb052f77cbc",
            "c1a631d3797f4c8ba720c5d57f00a0c3",
            "42c27d3d918a4ebba3e894b26edc2a77",
            "33ae6e60c1c04c918e0ca3c49b0e6544",
            "d2cff4ab1d144e83b0981c793d4932da",
            "50db32c463214f0ebcacf2bae715f6e1",
            "9b037a798ca3452fa739df8efde597f5",
            "d472a5462eec4ad6b42be2dd7c0ebdce",
            "33140b26af714794888add312625335b",
            "def429af9eb940b5bd940ea3901aefbb",
            "7d9e326638444018aa1891b37ad19027",
            "27c379587bd24b7a87419e8c2014e728",
            "6f5eeb76ef7c4c868e11aec8d2a15c10",
            "705d0c3f78714291a18781ae0b4ff138",
            "793b8455e01446f2ba1ae462918faec9",
            "0ff96889ae924b13855f099e07ffdca4",
            "6a9fffddc1cd40109329c4ec329cb709",
            "661d5b3b0a24457dbd6077ba6e3a51ec",
            "a430d52edf6a4ac983a99fc3f9e4fde6",
            "b6bac28b88bc44719eeba62ff594cf20",
            "ac4726eace9f4f8d862ba3ffda8b1bbb"
          ]
        },
        "id": "o4zdT4g3sX8n",
        "outputId": "2bf5386a-125f-4263-b425-f25c52966b13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb38e41245ca408582655db2f6b6a25a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf8a4105e0454fbda4323adef4be595d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf649ab03cfc4040b4a08c0e5bc499af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cb20e8766b940c7a31c43de9c7fd464",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d9e326638444018aa1891b37ad19027",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exploring hyperparams\n",
        "help(model.generate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI0Na3BxuBtO",
        "outputId": "22fd4330-c4bc-4b77-d785-f94ec0fb224a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method generate in module transformers.generation_utils:\n",
            "\n",
            "generate(inputs: Union[torch.Tensor, NoneType] = None, max_length: Union[int, NoneType] = None, min_length: Union[int, NoneType] = None, do_sample: Union[bool, NoneType] = None, early_stopping: Union[bool, NoneType] = None, num_beams: Union[int, NoneType] = None, temperature: Union[float, NoneType] = None, top_k: Union[int, NoneType] = None, top_p: Union[float, NoneType] = None, repetition_penalty: Union[float, NoneType] = None, bad_words_ids: Union[Iterable[int], NoneType] = None, bos_token_id: Union[int, NoneType] = None, pad_token_id: Union[int, NoneType] = None, eos_token_id: Union[int, NoneType] = None, length_penalty: Union[float, NoneType] = None, no_repeat_ngram_size: Union[int, NoneType] = None, encoder_no_repeat_ngram_size: Union[int, NoneType] = None, num_return_sequences: Union[int, NoneType] = None, max_time: Union[float, NoneType] = None, max_new_tokens: Union[int, NoneType] = None, decoder_start_token_id: Union[int, NoneType] = None, use_cache: Union[bool, NoneType] = None, num_beam_groups: Union[int, NoneType] = None, diversity_penalty: Union[float, NoneType] = None, prefix_allowed_tokens_fn: Union[Callable[[int, torch.Tensor], List[int]], NoneType] = None, logits_processor: Union[transformers.generation_logits_process.LogitsProcessorList, NoneType] = [], stopping_criteria: Union[transformers.generation_stopping_criteria.StoppingCriteriaList, NoneType] = [], output_attentions: Union[bool, NoneType] = None, output_hidden_states: Union[bool, NoneType] = None, output_scores: Union[bool, NoneType] = None, return_dict_in_generate: Union[bool, NoneType] = None, forced_bos_token_id: Union[int, NoneType] = None, forced_eos_token_id: Union[int, NoneType] = None, remove_invalid_values: Union[bool, NoneType] = None, synced_gpus: Union[bool, NoneType] = None, **model_kwargs) -> Union[transformers.generation_utils.GreedySearchEncoderDecoderOutput, transformers.generation_utils.GreedySearchDecoderOnlyOutput, transformers.generation_utils.SampleEncoderDecoderOutput, transformers.generation_utils.SampleDecoderOnlyOutput, transformers.generation_utils.BeamSearchEncoderDecoderOutput, transformers.generation_utils.BeamSearchDecoderOnlyOutput, transformers.generation_utils.BeamSampleEncoderDecoderOutput, transformers.generation_utils.BeamSampleDecoderOnlyOutput, torch.LongTensor] method of transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel instance\n",
            "    Generates sequences for models with a language modeling head. The method currently supports greedy decoding,\n",
            "    multinomial sampling, beam-search decoding, and beam-search multinomial sampling.\n",
            "    \n",
            "    Apart from `inputs`, all the arguments below will default to the value of the attribute of the same name\n",
            "    inside the [`PretrainedConfig`] of the model. The default values indicated are the default\n",
            "    values of those config.\n",
            "    \n",
            "    Most of these parameters are explained in more detail in [this blog post](https://huggingface.co/blog/how-to-generate).\n",
            "    \n",
            "    Parameters:\n",
            "    \n",
            "        inputs (`torch.Tensor` of shape `(batch_size, sequence_length)`, `(batch_size, sequence_length, feature_dim)` or `(batch_size, num_channels, height, width)`, *optional*):\n",
            "            The sequence used as a prompt for the generation or as model inputs to the encoder. If `None` the\n",
            "            method initializes it with `bos_token_id` and a batch size of 1. For decoder-only models\n",
            "            `inputs` should of in the format of `input_ids`. For encoder-decoder models *inputs* can\n",
            "            represent any of `input_ids`, `input_values`, `input_features`, or `pixel_values`.\n",
            "        max_length (`int`, *optional*, defaults to `model.config.max_length`):\n",
            "            The maximum length of the sequence to be generated.\n",
            "        max_new_tokens (`int`, *optional*, defaults to None):\n",
            "            The maximum numbers of tokens to generate, ignore the current number of tokens. Use either\n",
            "            `max_new_tokens` or `max_length` but not both, they serve the same purpose.\n",
            "        min_length (`int`, *optional*, defaults to 10):\n",
            "            The minimum length of the sequence to be generated.\n",
            "        do_sample (`bool`, *optional*, defaults to `False`):\n",
            "            Whether or not to use sampling ; use greedy decoding otherwise.\n",
            "        early_stopping (`bool`, *optional*, defaults to `False`):\n",
            "            Whether to stop the beam search when at least `num_beams` sentences are finished per batch or not.\n",
            "        num_beams (`int`, *optional*, defaults to 1):\n",
            "            Number of beams for beam search. 1 means no beam search.\n",
            "        temperature (`float`, *optional*, defaults to 1.0):\n",
            "            The value used to module the next token probabilities.\n",
            "        top_k (`int`, *optional*, defaults to 50):\n",
            "            The number of highest probability vocabulary tokens to keep for top-k-filtering.\n",
            "        top_p (`float`, *optional*, defaults to 1.0):\n",
            "            If set to float < 1, only the most probable tokens with probabilities that add up to `top_p` or\n",
            "            higher are kept for generation.\n",
            "        repetition_penalty (`float`, *optional*, defaults to 1.0):\n",
            "            The parameter for repetition penalty. 1.0 means no penalty. See [this paper](https://arxiv.org/pdf/1909.05858.pdf) for more details.\n",
            "        pad_token_id (`int`, *optional*):\n",
            "            The id of the *padding* token.\n",
            "        bos_token_id (`int`, *optional*):\n",
            "            The id of the *beginning-of-sequence* token.\n",
            "        eos_token_id (`int`, *optional*):\n",
            "            The id of the *end-of-sequence* token.\n",
            "        length_penalty (`float`, *optional*, defaults to 1.0):\n",
            "            Exponential penalty to the length. 1.0 means no penalty. Set to values < 1.0 in order to encourage the\n",
            "            model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer\n",
            "            sequences.\n",
            "        no_repeat_ngram_size (`int`, *optional*, defaults to 0):\n",
            "            If set to int > 0, all ngrams of that size can only occur once.\n",
            "        encoder_no_repeat_ngram_size (`int`, *optional*, defaults to 0):\n",
            "            If set to int > 0, all ngrams of that size that occur in the `encoder_input_ids` cannot occur in the\n",
            "            `decoder_input_ids`.\n",
            "        bad_words_ids(`List[List[int]]`, *optional*):\n",
            "            List of token ids that are not allowed to be generated. In order to get the tokens of the words that\n",
            "            should not appear in the generated text, use `tokenizer(bad_word, add_prefix_space=True).input_ids`.\n",
            "        num_return_sequences(`int`, *optional*, defaults to 1):\n",
            "            The number of independently computed returned sequences for each element in the batch.\n",
            "        max_time(`float`, *optional*, defaults to None):\n",
            "            The maximum amount of time you allow the computation to run for in seconds. generation will still\n",
            "            finish the current pass after allocated time has been passed.\n",
            "        attention_mask (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
            "            Mask to avoid performing attention on padding token indices. Mask values are in `[0, 1]`, 1 for\n",
            "            tokens that are not masked, and 0 for masked tokens. If not provided, will default to a tensor the same\n",
            "            shape as `input_ids` that masks the pad token. [What are attention masks?](../glossary#attention-mask)\n",
            "        decoder_start_token_id (`int`, *optional*):\n",
            "            If an encoder-decoder model starts decoding with a different token than *bos*, the id of that token.\n",
            "        use_cache: (`bool`, *optional*, defaults to `True`):\n",
            "            Whether or not the model should use the past last key/values attentions (if applicable to the model) to\n",
            "            speed up decoding.\n",
            "        num_beam_groups (`int`, *optional*, defaults to 1):\n",
            "            Number of groups to divide `num_beams` into in order to ensure diversity among different groups of\n",
            "            beams. [this paper](https://arxiv.org/pdf/1610.02424.pdf) for more details.\n",
            "        diversity_penalty (`float`, *optional*, defaults to 0.0):\n",
            "            This value is subtracted from a beam's score if it generates a token same as any beam from other group\n",
            "            at a particular time. Note that `diversity_penalty` is only effective if `group beam search` is\n",
            "            enabled.\n",
            "        prefix_allowed_tokens_fn: (`Callable[[int, torch.Tensor], List[int]]`, *optional*):\n",
            "            If provided, this function constraints the beam search to allowed tokens only at each step. If not\n",
            "            provided no constraint is applied. This function takes 2 arguments: the batch ID `batch_id` and\n",
            "            `input_ids`. It has to return a list with the allowed tokens for the next generation step\n",
            "            conditioned on the batch ID `batch_id` and the previously generated tokens `inputs_ids`. This\n",
            "            argument is useful for constrained generation conditioned on the prefix, as described in\n",
            "            [Autoregressive Entity Retrieval](https://arxiv.org/abs/2010.00904).\n",
            "        logits_processor (`LogitsProcessorList`, *optional*):\n",
            "             Custom logits processors that complement the default logits processors built from arguments and a\n",
            "             model's config. If a logit processor is passed that is already created with the arguments or a model's\n",
            "             config an error is thrown. This feature is intended for advanced users.\n",
            "        stopping_criteria (`StoppingCriteriaList`, *optional*):\n",
            "             Custom stopping criteria that complement the default stopping criteria built from arguments and a\n",
            "             model's config. If a stopping criteria is passed that is already created with the arguments or a\n",
            "             model's config an error is thrown. This feature is intended for advanced users.\n",
            "        output_attentions (`bool`, *optional*, defaults to *False*):\n",
            "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
            "            returned tensors for more details.\n",
            "        output_hidden_states (`bool`, *optional*, defaults to *False*):\n",
            "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors\n",
            "            for more details.\n",
            "        output_scores (`bool`, *optional*, defaults to *False*):\n",
            "            Whether or not to return the prediction scores. See `scores` under returned tensors for more details.\n",
            "        return_dict_in_generate (`bool`, *optional*, defaults to *False*):\n",
            "            Whether or not to return a [`~file_utils.ModelOutput`] instead of a plain tuple.\n",
            "        forced_bos_token_id (`int`, *optional*):\n",
            "            The id of the token to force as the first generated token after the `decoder_start_token_id`.\n",
            "            Useful for multilingual models like [mBART](../model_doc/mbart) where the first generated token\n",
            "            needs to be the target language token.\n",
            "        forced_eos_token_id (`int`, *optional*):\n",
            "            The id of the token to force as the last generated token when `max_length` is reached.\n",
            "        remove_invalid_values (`bool`, *optional*):\n",
            "            Whether to remove possible *nan* and *inf* outputs of the model to prevent the generation method to\n",
            "            crash. Note that using `remove_invalid_values` can slow down generation.\n",
            "        synced_gpus (`bool`, *optional*, defaults to `False`):\n",
            "            Whether to continue running the while loop until max_length (needed for ZeRO stage 3)\n",
            "    \n",
            "        model_kwargs:\n",
            "            Additional model specific kwargs will be forwarded to the `forward` function of the model. If the\n",
            "            model is an encoder-decoder model, encoder specific kwargs should not be prefixed and decoder specific\n",
            "            kwargs should be prefixed with *decoder_*.\n",
            "    \n",
            "    Return:\n",
            "        [`~file_utils.ModelOutput`] or `torch.LongTensor`: A\n",
            "        [`~file_utils.ModelOutput`] (if `return_dict_in_generate=True` or when\n",
            "        `config.return_dict_in_generate=True`) or a `torch.FloatTensor`.\n",
            "    \n",
            "            If the model is *not* an encoder-decoder model (`model.config.is_encoder_decoder=False`), the\n",
            "            possible [`~file_utils.ModelOutput`] types are:\n",
            "    \n",
            "                - [`~generation_utils.GreedySearchDecoderOnlyOutput`],\n",
            "                - [`~generation_utils.SampleDecoderOnlyOutput`],\n",
            "                - [`~generation_utils.BeamSearchDecoderOnlyOutput`],\n",
            "                - [`~generation_utils.BeamSampleDecoderOnlyOutput`]\n",
            "    \n",
            "            If the model is an encoder-decoder model (`model.config.is_encoder_decoder=True`), the possible\n",
            "            [`~file_utils.ModelOutput`] types are:\n",
            "    \n",
            "                - [`~generation_utils.GreedySearchEncoderDecoderOutput`],\n",
            "                - [`~generation_utils.SampleEncoderDecoderOutput`],\n",
            "                - [`~generation_utils.BeamSearchEncoderDecoderOutput`],\n",
            "                - [`~generation_utils.BeamSampleEncoderDecoderOutput`]\n",
            "    \n",
            "    Examples:\n",
            "    \n",
            "    ```python\n",
            "    >>> from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
            "    \n",
            "    >>> tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
            "    >>> model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
            "    >>> # do greedy decoding without providing a prompt\n",
            "    >>> outputs = model.generate(max_length=40)\n",
            "    >>> print(\"Generated:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
            "    \n",
            "    >>> tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
            "    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
            "    >>> document = (\n",
            "    ... \"at least two people were killed in a suspected bomb attack on a passenger bus \"\n",
            "    ... \"in the strife-torn southern philippines on monday , the military said.\"\n",
            "    ... )\n",
            "    >>> # encode input context\n",
            "    >>> input_ids = tokenizer(document, return_tensors=\"pt\").input_ids\n",
            "    >>> # generate 3 independent sequences using beam search decoding (5 beams)\n",
            "    >>> # with T5 encoder-decoder model conditioned on short news article.\n",
            "    >>> outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3)\n",
            "    >>> print(\"Generated:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
            "    \n",
            "    >>> tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
            "    >>> model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
            "    >>> input_context = \"The dog\"\n",
            "    >>> # encode input context\n",
            "    >>> input_ids = tokenizer(input_context, return_tensors=\"pt\").input_ids\n",
            "    >>> # generate 3 candidates using sampling\n",
            "    >>> outputs = model.generate(input_ids=input_ids, max_length=20, num_return_sequences=3, do_sample=True)\n",
            "    >>> print(\"Generated:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
            "    \n",
            "    >>> tokenizer = AutoTokenizer.from_pretrained(\"ctrl\")\n",
            "    >>> model = AutoModelForCausalLM.from_pretrained(\"ctrl\")\n",
            "    >>> # \"Legal\" is one of the control codes for ctrl\n",
            "    >>> input_context = \"Legal My neighbor is\"\n",
            "    >>> # encode input context\n",
            "    >>> input_ids = tokenizer(input_context, return_tensors=\"pt\").input_ids\n",
            "    >>> outputs = model.generate(input_ids=input_ids, max_length=20, repetition_penalty=1.2)\n",
            "    >>> print(\"Generated:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
            "    \n",
            "    >>> tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=False)\n",
            "    >>> model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
            "    >>> input_context = \"My cute dog\"\n",
            "    >>> # get tokens of words that should not be generated\n",
            "    >>> bad_words_ids = tokenizer([\"idiot\", \"stupid\", \"shut up\"], add_prefix_space=True).input_ids\n",
            "    >>> # encode input context\n",
            "    >>> input_ids = tokenizer(input_context, return_tensors=\"pt\").input_ids\n",
            "    >>> # generate sequences without allowing bad_words to be generated\n",
            "    >>> outputs = model.generate(input_ids=input_ids, max_length=20, do_sample=True, bad_words_ids=bad_words_ids)\n",
            "    >>> print(\"Generated:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
            "    ```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyOr7UqB-vwi",
        "outputId": "24a7e335-4058-4f27-85a1-826554dd2965"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 13 13:31:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/run_lm_finetuning.py\n",
        "\n",
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
        "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"\n",
        "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
        "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
        "using a masked language modeling (MLM) loss.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    BertConfig,\n",
        "    BertForMaskedLM,\n",
        "    BertTokenizer,\n",
        "    CamembertConfig,\n",
        "    CamembertForMaskedLM,\n",
        "    CamembertTokenizer,\n",
        "    DistilBertConfig,\n",
        "    DistilBertForMaskedLM,\n",
        "    DistilBertTokenizer,\n",
        "    GPT2Config,\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    OpenAIGPTConfig,\n",
        "    OpenAIGPTLMHeadModel,\n",
        "    OpenAIGPTTokenizer,\n",
        "    PreTrainedTokenizer,\n",
        "    RobertaConfig,\n",
        "    RobertaForMaskedLM,\n",
        "    RobertaTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"gpt2\": (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer),\n",
        "    \"openai-gpt\": (OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer),\n",
        "    \"bert\": (BertConfig, BertForMaskedLM, BertTokenizer),\n",
        "    \"roberta\": (RobertaConfig, RobertaForMaskedLM, RobertaTokenizer),\n",
        "    \"distilbert\": (DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer),\n",
        "    \"camembert\": (CamembertConfig, CamembertForMaskedLM, CamembertTokenizer),\n",
        "}\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, args, file_path=\"train\", block_size=512):\n",
        "        assert os.path.isfile(file_path)\n",
        "        directory, filename = os.path.split(file_path)\n",
        "        cached_features_file = os.path.join(\n",
        "            directory, args.model_name_or_path + \"_cached_lm_\" + str(block_size) + \"_\" + filename\n",
        "        )\n",
        "\n",
        "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
        "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"rb\") as handle:\n",
        "                self.examples = pickle.load(handle)\n",
        "        else:\n",
        "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
        "\n",
        "            self.examples = []\n",
        "            with open(file_path, encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "\n",
        "            tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
        "\n",
        "            for i in range(0, len(tokenized_text) - block_size + 1, block_size):  # Truncate in block of block_size\n",
        "                self.examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i : i + block_size]))\n",
        "            # Note that we are loosing the last truncated example here for the sake of simplicity (no padding)\n",
        "            # If your dataset is small, first you should loook for a bigger one :-) and second you\n",
        "            # can change this behavior by adding (model specific) padding.\n",
        "\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"wb\") as handle:\n",
        "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.examples[item])\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, evaluate=False):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer,\n",
        "        args,\n",
        "        file_path=args.eval_data_file if evaluate else args.train_data_file,\n",
        "        block_size=args.block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def _rotate_checkpoints(args, checkpoint_prefix, use_mtime=False):\n",
        "    if not args.save_total_limit:\n",
        "        return\n",
        "    if args.save_total_limit <= 0:\n",
        "        return\n",
        "\n",
        "    # Check if we should delete older checkpoint(s)\n",
        "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
        "    if len(glob_checkpoints) <= args.save_total_limit:\n",
        "        return\n",
        "\n",
        "    ordering_and_checkpoint_path = []\n",
        "    for path in glob_checkpoints:\n",
        "        if use_mtime:\n",
        "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
        "        else:\n",
        "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
        "            if regex_match and regex_match.groups():\n",
        "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
        "\n",
        "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
        "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
        "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
        "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
        "    for checkpoint in checkpoints_to_be_deleted:\n",
        "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
        "        shutil.rmtree(checkpoint)\n",
        "\n",
        "\n",
        "def mask_tokens(inputs: torch.Tensor, tokenizer: PreTrainedTokenizer, args) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
        "    labels = inputs.clone()\n",
        "    # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
        "    probability_matrix = torch.full(labels.shape, args.mlm_probability)\n",
        "    special_tokens_mask = [\n",
        "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
        "    ]\n",
        "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels\n",
        "\n",
        "\n",
        "def train(args, train_dataset, model, tokenizer):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if os.path.exists(args.model_name_or_path):\n",
        "        try:\n",
        "            # set global_step to gobal_step of last saved checkpoint from model path\n",
        "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
        "            global_step = int(checkpoint_suffix)\n",
        "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "        except ValueError:\n",
        "            logger.info(\"  Starting fine-tuning.\")\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "\n",
        "    model_to_resize = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
        "    model_to_resize.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproducibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            inputs, labels = mask_tokens(batch, tokenizer, args) if args.mlm else (batch, batch)\n",
        "            inputs = inputs.to(args.device)\n",
        "            labels = labels.to(args.device)\n",
        "            model.train()\n",
        "            outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
        "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
        "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    checkpoint_prefix = \"checkpoint\"\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
        "\n",
        "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "\n",
        "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_output_dir = args.output_dir\n",
        "\n",
        "    eval_dataset = load_and_cache_examples(args, tokenizer, evaluate=True)\n",
        "\n",
        "    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "        os.makedirs(eval_output_dir)\n",
        "\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "    # multi-gpu evaluate\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    model.eval()\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        inputs, labels = mask_tokens(batch, tokenizer, args) if args.mlm else (batch, batch)\n",
        "        inputs = inputs.to(args.device)\n",
        "        labels = labels.to(args.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n",
        "            lm_loss = outputs[0]\n",
        "            eval_loss += lm_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
        "\n",
        "    result = {\"perplexity\": perplexity}\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--train_data_file\", default=None, type=str, required=True, help=\"The input training data file (a text file).\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "\n",
        "    # Other parameters\n",
        "    parser.add_argument(\n",
        "        \"--eval_data_file\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\"--model_type\", default=\"bert\", type=str, help=\"The model architecture to be fine-tuned.\")\n",
        "    parser.add_argument(\n",
        "        \"--model_name_or_path\",\n",
        "        default=\"bert-base-cased\",\n",
        "        type=str,\n",
        "        help=\"The model checkpoint for weights initialization.\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--mlm\", action=\"store_true\", help=\"Train with masked-language modeling loss instead of language modeling.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--mlm_probability\", type=float, default=0.15, help=\"Ratio of tokens to mask for masked language modeling loss\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--config_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Optional pretrained config name or path if not the same as model_name_or_path\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cache_dir\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--block_size\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"Optional input sequence length after tokenization.\"\n",
        "        \"The training dataset will be truncated in block of this size for training.\"\n",
        "        \"Default to the model max input length for single sentence inputs (take into account special tokens).\",\n",
        "    )\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
        "    parser.add_argument(\n",
        "        \"--evaluate_during_training\", action=\"store_true\", help=\"Run evaluation during training at each logging step.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\"--per_gpu_train_batch_size\", default=4, type=int, help=\"Batch size per GPU/CPU for training.\")\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_eval_batch_size\", default=4, type=int, help=\"Batch size per GPU/CPU for evaluation.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_train_epochs\", default=1.0, type=float, help=\"Total number of training epochs to perform.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_steps\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "    parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\")\n",
        "    parser.add_argument(\"--save_steps\", type=int, default=50, help=\"Save checkpoint every X updates steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--save_total_limit\",\n",
        "        type=int,\n",
        "        default=None,\n",
        "        help=\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--eval_all_checkpoints\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\",\n",
        "    )\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\"\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--fp16\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--fp16_opt_level\",\n",
        "        type=str,\n",
        "        default=\"O1\",\n",
        "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
        "    )\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
        "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.model_type in [\"bert\", \"roberta\", \"distilbert\", \"camembert\"] and not args.mlm:\n",
        "        raise ValueError(\n",
        "            \"BERT and RoBERTa do not have LM heads but masked LM heads. They must be run using the --mlm \"\n",
        "            \"flag (masked language modeling).\"\n",
        "        )\n",
        "    if args.eval_data_file is None and args.do_eval:\n",
        "        raise ValueError(\n",
        "            \"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"\n",
        "            \"or remove the --do_eval argument.\"\n",
        "        )\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup distant debugging if needed\n",
        "    if args.server_ip and args.server_port:\n",
        "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
        "        import ptvsd\n",
        "\n",
        "        print(\"Waiting for debugger attach\")\n",
        "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
        "        ptvsd.wait_for_attach()\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend=\"nccl\")\n",
        "        args.n_gpu = 1\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    if args.local_rank not in [-1, 0]:\n",
        "        torch.distributed.barrier()  # Barrier to make sure only the first process in distributed training download model & vocab\n",
        "\n",
        "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
        "    config = config_class.from_pretrained(\n",
        "        args.config_name if args.config_name else args.model_name_or_path,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer = tokenizer_class.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
        "        do_lower_case=args.do_lower_case,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    if args.block_size <= 0:\n",
        "        args.block_size = (\n",
        "            tokenizer.max_len_single_sentence\n",
        "        )  # Our input block size will be the max possible for the model\n",
        "    args.block_size = min(args.block_size, tokenizer.max_len_single_sentence)\n",
        "    model = model_class.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "        config=config,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    model.to(args.device)\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        torch.distributed.barrier()  # End of barrier to make sure only the first process in distributed training download model & vocab\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        if args.local_rank not in [-1, 0]:\n",
        "            torch.distributed.barrier()  # Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False)\n",
        "\n",
        "        if args.local_rank == 0:\n",
        "            torch.distributed.barrier()\n",
        "\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
        "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(args.output_dir)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = (\n",
        "            model.module if hasattr(model, \"module\") else model\n",
        "        )  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(args.output_dir)\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        model = model_class.from_pretrained(args.output_dir)\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "        model.to(args.device)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            model = model_class.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKnAhsuD6hgE",
        "outputId": "f5ee43b5-bf8c-4edd-ef91-183d45ed874a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/run_lm_finetuning.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_experiments.sh\n",
        "mkdir -p experiments\n",
        "\n",
        "for epoch in 10\n",
        "do\n",
        "  python src/run_lm_finetuning.py \\\n",
        "  --model_name_or_path distilgpt2 \\\n",
        "  --model_type gpt2 \\\n",
        "  --train_data_file data/train.txt \\\n",
        "  --output_dir experiments/epochs_$epoch \\\n",
        "  --do_train \\\n",
        "  --overwrite_output_dir \\\n",
        "  --per_gpu_train_batch_size 1 \\\n",
        "  --num_train_epochs $epoch\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj43mMW0x0Ex",
        "outputId": "ddfee661-e5d9-4efc-ac47-31a570f6047e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_experiments.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start fine tuning \n",
        "# !bash run_experiments.sh"
      ],
      "metadata": {
        "id": "hQgzTAku_AhR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install gpt-2-simple > /dev/null\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n",
        "\n",
        "model_name = \"124M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "\tprint(f\"Downloading {model_name} model...\")\n",
        "\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under models/124M/\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              'data/train.txt',\n",
        "              model_name=model_name,\n",
        "              steps=1000)   # steps is max number of training steps\n",
        "\n",
        "gpt2.generate(sess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqymrRxUPXGg",
        "outputId": "6029a1ef-2998-40bb-86c2-c7f8f80ef56a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 124M model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 510Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 2.23Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 802Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:20, 24.8Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 624Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 2.90Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 2.88Mit/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [03:53<00:00, 233.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 47679113 tokens\n",
            "Training...\n",
            "[1 | 5.87] loss=2.29 avg=2.29\n",
            "[2 | 7.15] loss=2.35 avg=2.32\n",
            "[3 | 8.43] loss=2.09 avg=2.24\n",
            "[4 | 9.71] loss=2.30 avg=2.26\n",
            "[5 | 10.99] loss=2.06 avg=2.22\n",
            "[6 | 12.27] loss=2.04 avg=2.19\n",
            "[7 | 13.54] loss=1.81 avg=2.13\n",
            "[8 | 14.82] loss=2.12 avg=2.13\n",
            "[9 | 16.10] loss=1.94 avg=2.11\n",
            "[10 | 17.38] loss=1.86 avg=2.08\n",
            "[11 | 18.65] loss=2.10 avg=2.08\n",
            "[12 | 19.93] loss=1.89 avg=2.07\n",
            "[13 | 21.21] loss=1.94 avg=2.06\n",
            "[14 | 22.49] loss=1.85 avg=2.04\n",
            "[15 | 23.76] loss=2.03 avg=2.04\n",
            "[16 | 25.04] loss=1.70 avg=2.02\n",
            "[17 | 26.32] loss=1.95 avg=2.01\n",
            "[18 | 27.60] loss=1.61 avg=1.99\n",
            "[19 | 28.87] loss=1.76 avg=1.98\n",
            "[20 | 30.15] loss=1.75 avg=1.96\n",
            "[21 | 31.43] loss=1.85 avg=1.96\n",
            "[22 | 32.70] loss=2.05 avg=1.96\n",
            "[23 | 33.98] loss=2.04 avg=1.97\n",
            "[24 | 35.26] loss=1.72 avg=1.95\n",
            "[25 | 36.53] loss=1.94 avg=1.95\n",
            "[26 | 37.81] loss=1.81 avg=1.95\n",
            "[27 | 39.08] loss=1.97 avg=1.95\n",
            "[28 | 40.36] loss=1.78 avg=1.94\n",
            "[29 | 41.64] loss=1.94 avg=1.94\n",
            "[30 | 42.91] loss=1.84 avg=1.94\n",
            "[31 | 44.19] loss=2.07 avg=1.94\n",
            "[32 | 45.46] loss=1.95 avg=1.94\n",
            "[33 | 46.74] loss=1.73 avg=1.93\n",
            "[34 | 48.02] loss=1.80 avg=1.93\n",
            "[35 | 49.29] loss=2.10 avg=1.94\n",
            "[36 | 50.57] loss=2.08 avg=1.94\n",
            "[37 | 51.85] loss=1.80 avg=1.94\n",
            "[38 | 53.12] loss=1.58 avg=1.92\n",
            "[39 | 54.40] loss=1.81 avg=1.92\n",
            "[40 | 55.67] loss=1.88 avg=1.92\n",
            "[41 | 56.95] loss=1.69 avg=1.91\n",
            "[42 | 58.23] loss=1.85 avg=1.91\n",
            "[43 | 59.50] loss=1.68 avg=1.90\n",
            "[44 | 60.78] loss=1.58 avg=1.90\n",
            "[45 | 62.06] loss=1.64 avg=1.89\n",
            "[46 | 63.33] loss=1.73 avg=1.88\n",
            "[47 | 64.61] loss=1.79 avg=1.88\n",
            "[48 | 65.88] loss=2.00 avg=1.88\n",
            "[49 | 67.16] loss=1.60 avg=1.88\n",
            "[50 | 68.43] loss=1.60 avg=1.87\n",
            "[51 | 69.71] loss=1.64 avg=1.86\n",
            "[52 | 70.98] loss=1.81 avg=1.86\n",
            "[53 | 72.26] loss=1.68 avg=1.86\n",
            "[54 | 73.54] loss=1.88 avg=1.86\n",
            "[55 | 74.81] loss=1.72 avg=1.86\n",
            "[56 | 76.09] loss=1.62 avg=1.85\n",
            "[57 | 77.36] loss=1.81 avg=1.85\n",
            "[58 | 78.64] loss=1.94 avg=1.85\n",
            "[59 | 79.92] loss=1.56 avg=1.84\n",
            "[60 | 81.19] loss=2.00 avg=1.85\n",
            "[61 | 82.47] loss=1.67 avg=1.84\n",
            "[62 | 83.75] loss=1.69 avg=1.84\n",
            "[63 | 85.03] loss=1.81 avg=1.84\n",
            "[64 | 86.31] loss=1.72 avg=1.84\n",
            "[65 | 87.58] loss=1.92 avg=1.84\n",
            "[66 | 88.86] loss=1.74 avg=1.84\n",
            "[67 | 90.14] loss=1.93 avg=1.84\n",
            "[68 | 91.41] loss=1.82 avg=1.84\n",
            "[69 | 92.69] loss=1.56 avg=1.83\n",
            "[70 | 93.96] loss=1.79 avg=1.83\n",
            "[71 | 95.24] loss=1.72 avg=1.83\n",
            "[72 | 96.52] loss=1.66 avg=1.83\n",
            "[73 | 97.79] loss=1.60 avg=1.82\n",
            "[74 | 99.07] loss=1.81 avg=1.82\n",
            "[75 | 100.34] loss=1.62 avg=1.82\n",
            "[76 | 101.62] loss=1.94 avg=1.82\n",
            "[77 | 102.89] loss=1.52 avg=1.82\n",
            "[78 | 104.17] loss=1.67 avg=1.81\n",
            "[79 | 105.45] loss=1.75 avg=1.81\n",
            "[80 | 106.72] loss=1.69 avg=1.81\n",
            "[81 | 108.00] loss=1.68 avg=1.81\n",
            "[82 | 109.27] loss=1.74 avg=1.81\n",
            "[83 | 110.55] loss=1.68 avg=1.80\n",
            "[84 | 111.82] loss=1.69 avg=1.80\n",
            "[85 | 113.10] loss=2.12 avg=1.81\n",
            "[86 | 114.37] loss=1.92 avg=1.81\n",
            "[87 | 115.65] loss=1.65 avg=1.81\n",
            "[88 | 116.92] loss=1.68 avg=1.80\n",
            "[89 | 118.20] loss=1.56 avg=1.80\n",
            "[90 | 119.47] loss=1.80 avg=1.80\n",
            "[91 | 120.75] loss=1.59 avg=1.80\n",
            "[92 | 122.02] loss=1.70 avg=1.80\n",
            "[93 | 123.30] loss=1.61 avg=1.79\n",
            "[94 | 124.58] loss=1.58 avg=1.79\n",
            "[95 | 125.85] loss=1.72 avg=1.79\n",
            "[96 | 127.13] loss=1.83 avg=1.79\n",
            "[97 | 128.40] loss=1.63 avg=1.79\n",
            "[98 | 129.68] loss=1.79 avg=1.79\n",
            "[99 | 130.95] loss=1.69 avg=1.78\n",
            "[100 | 132.23] loss=1.67 avg=1.78\n",
            "======== SAMPLE 1 ========\n",
            " packages.\n",
            "Put the milk in an ungreased 8x14x1st-cup pan. Grill until the butter and the sugar are melted, about 2 minutes.\n",
            "Bring a large pot of salted water to boil and stir the cream or coconut milk until the sugar is melted slightly, about 8 minutes. The syrup will drain a bit, but will stay on flavors.\n",
            "Put the spinach back in the bowl. Put the salad on top.\n",
            "Place your slices in the serving bowl and garnish with the mint leaves.\n",
            "<|endoftext|>\n",
            "olive oil salt medium onion red onion carrots or peas quart or large carrots of chopped parsley minced leek\n",
            "\n",
            "🥕Ingredients: \n",
            " 1/2 tablespoon olive oil \n",
            " 1 cup salt \n",
            " 1/8 teaspoon medium onion red onion, chopped \n",
            " 1 teaspoon carrots or peas \n",
            " 1/8 quart or large carrots of chopped parsley, finely chopped \n",
            " 3 teaspoons minced leek, or to taste (not all greens) \n",
            " \n",
            " \n",
            "📝Instructions: \n",
            "Stir the olive oil and salt in a large heavy skillet over medium heat. Saute the potatoes for 15 to 20 minutes or until tender. In a mixing bowl, stir in the red onion and carrots. The greens should have thickened. Transfer to a platter. Add the parsley and leek and cook over medium heat until a soft, almost-cooked char. Serve immediately or in the evening. <|endoftext|>\n",
            "water \n",
            "medium onion garlic cloves sugar salt olive oil garlic powder sugar small yellow peas salt\n",
            "\n",
            "🥕Ingredients: \n",
            " 2 tablespoons water \n",
            " 1 1/2 cups onion \n",
            " 1 teaspoon red onion \n",
            " 2 tablespoons carrots or peas, sliced \n",
            " 1 teaspoon minced leek \n",
            " \n",
            "📝Instructions: \n",
            "Toss onion and red onion in 1/2 cup water and cook in the pan until water is heated through. Drain, reserving just excess water to serve. Remove from pan and let cool slightly.\n",
            "Set aside.\n",
            "In a small saucepan, bring onions and carrots to a boil. Saute garlic, green beans, parsley, and peas until tender. Add leeks and leeks to the boil. Add the garlic, lemon juice, lime juice, and thyme to boiling over moderate heat until soft and stir in, 1 minute. Drain and return to the saucepan.\n",
            "Stir in the oil until golden. Transfer to a resealable container. Place in a warm large bowl, cover with the salad, and season with salt, salt, and pepper. Serve over the salad. <|endoftext|>\n",
            "garlic cloves garlic crushed black pepper salt ground black pepper garlic cloves garlic clove garlic garlic cloves ground cinnamon ground cinnamon ground cloves ground nutmeg ground\n",
            "\n",
            "🥕Ingredients: \n",
            " 4 cloves garlic, peeled \n",
            " 2 tablespoons crushed black pepper \n",
            " 2 teaspoons salt \n",
            " 1/2 teaspoon ground black pepper \n",
            " 3 teaspoons garlic, finely sliced \n",
            " 1 tablespoon crushed black pepper \n",
            " 1/2 tablespoon garlic clove \n",
            " 2 tablespoons garlic, finely sliced \n",
            " 1 teaspoon ground cinnamon \n",
            " 1/2 teaspoon 1/2 teaspoon ground cloves \n",
            " 1 teaspoon ground nutmeg \n",
            " \n",
            "📝Instructions: \n",
            "In a food processor, combine the garlic, black pepper, salt, black pepper, garlic, clove, garlic, garlic cloves, and cinnamon. In a separate bowl, combine all the remaining 2 tablespoons in the remaining 1/4 cup vinegar. Stir in the cloves, and season with cloves, salt, and black pepper. Using a 2-inch piece, heat the olive oil in a large saucepan over low heat until just hot. Add the garlic, garlic clove, garlic clove, and cinnamon to the pan. Cook, stirring often, until the cloves and garlic are just tender, 5 to 6 minutes. Drain and discard the vegetables with a few drops of salt.\n",
            "Cum the parsley in the lime juice and 1 tablespoon ground cinnamon. Add the 1/4 teaspoon salt. Cover the pan with aluminum foil and let the masa harina sit in the refrigerator 5 to 10 minutes. When the masa harina is completely cool, remove it from the masa and let cool a bit before eating. Drain, season with salt, pepper, salt, and ground cinnamon, and serve. <|endoftext|>\n",
            "carrado-size diced queso fresco sauce heavy cream\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 1/2 pounds carrado-size diced queso fresco sauce \n",
            " 1/2 cup heavy cream, plus more for seasoning (about 1 tablespoon)\n",
            " 1/4 cup (about 2 sticks) heavy cream for serving, divided\n",
            "📝Instructions: \n",
            "In a small bowl set aside.\n",
            "Preheat oven to 375°F.\n",
            "\n",
            "[101 | 145.98] loss=1.70 avg=1.78\n",
            "[102 | 147.25] loss=1.69 avg=1.78\n",
            "[103 | 148.53] loss=1.78 avg=1.78\n",
            "[104 | 149.81] loss=1.71 avg=1.78\n",
            "[105 | 151.08] loss=1.52 avg=1.77\n",
            "[106 | 152.36] loss=1.63 avg=1.77\n",
            "[107 | 153.63] loss=1.79 avg=1.77\n",
            "[108 | 154.91] loss=1.62 avg=1.77\n",
            "[109 | 156.18] loss=1.72 avg=1.77\n",
            "[110 | 157.46] loss=1.77 avg=1.77\n",
            "[111 | 158.73] loss=1.61 avg=1.77\n",
            "[112 | 160.01] loss=1.58 avg=1.76\n",
            "[113 | 161.29] loss=1.63 avg=1.76\n",
            "[114 | 162.56] loss=1.45 avg=1.76\n",
            "[115 | 163.84] loss=1.58 avg=1.76\n",
            "[116 | 165.12] loss=1.39 avg=1.75\n",
            "[117 | 166.39] loss=1.76 avg=1.75\n",
            "[118 | 167.67] loss=1.69 avg=1.75\n",
            "[119 | 168.94] loss=1.59 avg=1.75\n",
            "[120 | 170.22] loss=1.69 avg=1.75\n",
            "[121 | 171.49] loss=1.55 avg=1.74\n",
            "[122 | 172.77] loss=1.55 avg=1.74\n",
            "[123 | 174.05] loss=1.74 avg=1.74\n",
            "[124 | 175.32] loss=1.97 avg=1.74\n",
            "[125 | 176.60] loss=1.69 avg=1.74\n",
            "[126 | 177.87] loss=1.71 avg=1.74\n",
            "[127 | 179.15] loss=1.76 avg=1.74\n",
            "[128 | 180.43] loss=1.71 avg=1.74\n",
            "[129 | 181.70] loss=1.85 avg=1.74\n",
            "[130 | 182.98] loss=1.99 avg=1.75\n",
            "[131 | 184.26] loss=1.75 avg=1.75\n",
            "[132 | 185.53] loss=1.92 avg=1.75\n",
            "[133 | 186.81] loss=1.72 avg=1.75\n",
            "[134 | 188.08] loss=1.55 avg=1.75\n",
            "[135 | 189.36] loss=1.68 avg=1.75\n",
            "[136 | 190.64] loss=1.62 avg=1.74\n",
            "[137 | 191.91] loss=1.48 avg=1.74\n",
            "[138 | 193.19] loss=1.48 avg=1.74\n",
            "[139 | 194.46] loss=1.76 avg=1.74\n",
            "[140 | 195.74] loss=1.69 avg=1.74\n",
            "[141 | 197.01] loss=1.71 avg=1.74\n",
            "[142 | 198.29] loss=1.79 avg=1.74\n",
            "[143 | 199.57] loss=1.64 avg=1.74\n",
            "[144 | 200.85] loss=1.87 avg=1.74\n",
            "[145 | 202.12] loss=1.72 avg=1.74\n",
            "[146 | 203.40] loss=1.70 avg=1.74\n",
            "[147 | 204.68] loss=1.56 avg=1.73\n",
            "[148 | 205.96] loss=1.70 avg=1.73\n",
            "[149 | 207.23] loss=1.43 avg=1.73\n",
            "[150 | 208.51] loss=1.85 avg=1.73\n",
            "[151 | 209.79] loss=1.58 avg=1.73\n",
            "[152 | 211.06] loss=1.45 avg=1.73\n",
            "[153 | 212.34] loss=1.61 avg=1.72\n",
            "[154 | 213.62] loss=1.54 avg=1.72\n",
            "[155 | 214.89] loss=1.85 avg=1.72\n",
            "[156 | 216.17] loss=1.69 avg=1.72\n",
            "[157 | 217.44] loss=1.52 avg=1.72\n",
            "[158 | 218.72] loss=1.52 avg=1.72\n",
            "[159 | 220.00] loss=1.77 avg=1.72\n",
            "[160 | 221.27] loss=1.72 avg=1.72\n",
            "[161 | 222.55] loss=1.37 avg=1.71\n",
            "[162 | 223.82] loss=1.67 avg=1.71\n",
            "[163 | 225.10] loss=1.62 avg=1.71\n",
            "[164 | 226.38] loss=1.50 avg=1.71\n",
            "[165 | 227.66] loss=1.63 avg=1.71\n",
            "[166 | 228.93] loss=1.77 avg=1.71\n",
            "[167 | 230.21] loss=1.78 avg=1.71\n",
            "[168 | 231.49] loss=1.79 avg=1.71\n",
            "[169 | 232.76] loss=1.68 avg=1.71\n",
            "[170 | 234.04] loss=1.66 avg=1.71\n",
            "[171 | 235.32] loss=1.66 avg=1.71\n",
            "[172 | 236.60] loss=1.48 avg=1.71\n",
            "[173 | 237.87] loss=1.69 avg=1.71\n",
            "[174 | 239.15] loss=1.70 avg=1.71\n",
            "[175 | 240.43] loss=1.60 avg=1.71\n",
            "[176 | 241.70] loss=1.55 avg=1.70\n",
            "[177 | 242.98] loss=1.37 avg=1.70\n",
            "[178 | 244.25] loss=1.59 avg=1.70\n",
            "[179 | 245.53] loss=1.44 avg=1.70\n",
            "[180 | 246.81] loss=1.66 avg=1.70\n",
            "[181 | 248.08] loss=1.60 avg=1.69\n",
            "[182 | 249.36] loss=1.62 avg=1.69\n",
            "[183 | 250.63] loss=1.65 avg=1.69\n",
            "[184 | 251.91] loss=1.42 avg=1.69\n",
            "[185 | 253.18] loss=1.59 avg=1.69\n",
            "[186 | 254.46] loss=1.61 avg=1.69\n",
            "[187 | 255.74] loss=1.73 avg=1.69\n",
            "[188 | 257.01] loss=1.57 avg=1.69\n",
            "[189 | 258.29] loss=1.62 avg=1.69\n",
            "[190 | 259.57] loss=1.67 avg=1.69\n",
            "[191 | 260.84] loss=1.38 avg=1.68\n",
            "[192 | 262.12] loss=1.52 avg=1.68\n",
            "[193 | 263.39] loss=1.77 avg=1.68\n",
            "[194 | 264.67] loss=1.45 avg=1.68\n",
            "[195 | 265.95] loss=1.31 avg=1.67\n",
            "[196 | 267.23] loss=1.36 avg=1.67\n",
            "[197 | 268.50] loss=1.44 avg=1.67\n",
            "[198 | 269.78] loss=1.69 avg=1.67\n",
            "[199 | 271.05] loss=1.75 avg=1.67\n",
            "[200 | 272.33] loss=1.44 avg=1.67\n",
            "======== SAMPLE 1 ========\n",
            " Wish on a large piece of cheese and gently flatten it out until evenly rolled and cooled.\n",
            "Preheat oven to 400 degrees. Lightly grease a 12-inch cake pan.\n",
            "Combine honey, vanilla, salt and ground black pepper in a bowl; place on a large baking sheet and lightly oil each side of the cake pan, then top with a lightly flour ladle. Toss the honey with a splash of flour. Spread over the bottom of the cake pan, then sprinkle with sugar. Bake for 1 hour in the preheated oven until a toothpick inserted into the center of the cake comes out clean, 12 to 13 minutes. Remove before serving.\n",
            " <|endoftext|>\n",
            "pâchella flour white sugar brown sugar baking cream ground cinnamon ground ginger ground cloves coarsely shredded bread flour butter lemon juice\n",
            "\n",
            "🥕Ingredients: \n",
            " 3 pounds pâchella flour \n",
            " 2 cups white sugar \n",
            " 2 cups brown sugar \n",
            " 1 cup baking cream \n",
            " 1 tablespoon ground cinnamon \n",
            " 1/2 teaspoon ground ginger \n",
            " 1/4 teaspoon ground cloves \n",
            " 1/4 teaspoon grated nutmeg \n",
            " 1 cup flour \n",
            " 1 cup butter \n",
            " 1 1/2-cup lemon juice\n",
            "📝Instructions: \n",
            "Combine flour, white sugar, brown sugar, baking cream and 1 teaspoon of cinnamon in a bowl. In a blender, puree flour mixture until flour and sugar blend great. Divide batter into six portions. Pour flour mixture into 1 bowl (do not over mix if needed). Fold batter in third half of batter just before making third. Shape batter to cup, then scoop batter onto prepared baking sheet. Bake with risen or falling cake cupcakes on a parchment-lined baking sheet until top edges are golden brown, 12 to 15 minutes. Cool on baking sheet for 12 hours before pressing against paper-lined edge.\n",
            "Combine flour, white sugar, brown sugar, baking cream and 1 teaspoon of cinnamon in a bowl. In a blender, puree flour mixture until flour and sugar blend great. Divide batter into six portions. Pour flour mixture into 1 bowl (do not over mix if needed). Fold batter in third half of batter just before making third.\n",
            "Shape batter to cup, then scoop batter onto prepared baking sheet.\n",
            "Bake with risen or falling cake cupcakes on a parchment-lined baking sheet until top edges are golden brown, 12 to 15 minutes. Cool on baking sheet for 12 hours before pressing against paper-lined edge. <|endoftext|>\n",
            "small onion cloves garlic honey ground cinnamon honey white wine milk extra-virgin olive oil Salt black pepper\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 small onion, minced \n",
            " 5 cloves garlic, crushed \n",
            " 5 tablespoons honey \n",
            " 1 teaspoon ground cinnamon \n",
            " 1/3 cup honey \n",
            " 1 cup white wine \n",
            " 2 ounces milk \n",
            " 1/4 cup extra-virgin olive oil \n",
            " Salt \n",
            " 6 tablespoons black pepper\n",
            "📝Instructions: \n",
            "Slice the onion in half lengthwise. Peel the garlic and remove some from the onion. Use a wide-dish knife to cut each part off the onion with a serrated-edged knife, and then slice them into 1/4-inch thick slices. Divide the garlic among their portions.\n",
            "Slice the onion in half lengthwise. Peel the garlic and remove some from the onion. Use a wide-dish knife to cut each part off the onion with a serrated-edged knife, and then slice the slices into 1/4-inch thick slices. Divide the garlic among their portions. <|endoftext|>\n",
            "medium onion dry white wine white vinegar black whole almonds sugar extra-virgin olive oil ground cinnamon ground nutmeg sugar whole whole nuts chopped white grapeseed butter garlic powder ground all-purpose flour salt whole-whey wheat flour sugar baking powder baking soda sugar\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 tablespoon medium onion, softened \n",
            " 3/4 cup dry white wine \n",
            " 1/4 cup white vinegar \n",
            " 1 cup black whole almonds \n",
            " 1/2 cup sugar \n",
            " 1/2 cup plus 1/4 teaspoon sugar \n",
            " 3/4 cup whole nuts \n",
            " 1 tablespoon chopped white grapeseed \n",
            " 1/2 teaspoon butter \n",
            " 2 tablespoons garlic powder \n",
            " 1/2 teaspoon ground all-purpose flour \n",
            " 1 teaspoon salt \n",
            " 1/2 teaspoon whole-whey wheat flour \n",
            " 1 teaspoon sugar \n",
            " 1/4 teaspoon baking powder \n",
            " 1/2 teaspoon baking soda \n",
            " 1/2 teaspoon sugar\n",
            "📝Instructions: \n",
            "Prepare the oven to 450 degrees F (200 degrees C). Line a large serving pan with a damp towel and grease it with oil. Pour this oil into a medium bowl and whisk it well. Pour the dry wine, vinegar, and some sugar into the bowl with a teaspoon of the oil. Pour it into the baking\n",
            "\n",
            "[201 | 285.12] loss=1.47 avg=1.66\n",
            "[202 | 286.40] loss=1.55 avg=1.66\n",
            "[203 | 287.68] loss=1.54 avg=1.66\n",
            "[204 | 288.95] loss=1.34 avg=1.66\n",
            "[205 | 290.23] loss=1.73 avg=1.66\n",
            "[206 | 291.51] loss=1.80 avg=1.66\n",
            "[207 | 292.78] loss=1.46 avg=1.66\n",
            "[208 | 294.06] loss=1.88 avg=1.66\n",
            "[209 | 295.34] loss=1.65 avg=1.66\n",
            "[210 | 296.61] loss=1.60 avg=1.66\n",
            "[211 | 297.89] loss=1.56 avg=1.66\n",
            "[212 | 299.17] loss=1.70 avg=1.66\n",
            "[213 | 300.44] loss=1.83 avg=1.66\n",
            "[214 | 301.72] loss=1.87 avg=1.66\n",
            "[215 | 303.00] loss=1.43 avg=1.66\n",
            "[216 | 304.27] loss=1.37 avg=1.66\n",
            "[217 | 305.55] loss=1.53 avg=1.66\n",
            "[218 | 306.83] loss=1.43 avg=1.65\n",
            "[219 | 308.10] loss=1.52 avg=1.65\n",
            "[220 | 309.38] loss=1.53 avg=1.65\n",
            "[221 | 310.65] loss=1.74 avg=1.65\n",
            "[222 | 311.93] loss=1.67 avg=1.65\n",
            "[223 | 313.21] loss=1.76 avg=1.65\n",
            "[224 | 314.48] loss=1.70 avg=1.65\n",
            "[225 | 315.76] loss=1.56 avg=1.65\n",
            "[226 | 317.03] loss=1.61 avg=1.65\n",
            "[227 | 318.31] loss=1.93 avg=1.65\n",
            "[228 | 319.59] loss=1.60 avg=1.65\n",
            "[229 | 320.87] loss=1.38 avg=1.65\n",
            "[230 | 322.14] loss=1.51 avg=1.65\n",
            "[231 | 323.42] loss=1.82 avg=1.65\n",
            "[232 | 324.70] loss=1.40 avg=1.65\n",
            "[233 | 325.98] loss=1.68 avg=1.65\n",
            "[234 | 327.25] loss=1.44 avg=1.65\n",
            "[235 | 328.53] loss=1.56 avg=1.65\n",
            "[236 | 329.81] loss=1.50 avg=1.64\n",
            "[237 | 331.08] loss=1.41 avg=1.64\n",
            "[238 | 332.36] loss=1.78 avg=1.64\n",
            "[239 | 333.64] loss=1.44 avg=1.64\n",
            "[240 | 334.91] loss=1.63 avg=1.64\n",
            "[241 | 336.19] loss=1.78 avg=1.64\n",
            "[242 | 337.46] loss=1.69 avg=1.64\n",
            "[243 | 338.74] loss=1.53 avg=1.64\n",
            "[244 | 340.02] loss=1.62 avg=1.64\n",
            "[245 | 341.29] loss=1.54 avg=1.64\n",
            "[246 | 342.57] loss=1.52 avg=1.64\n",
            "[247 | 343.85] loss=1.63 avg=1.64\n",
            "[248 | 345.12] loss=1.36 avg=1.64\n",
            "[249 | 346.40] loss=1.71 avg=1.64\n",
            "[250 | 347.68] loss=1.67 avg=1.64\n",
            "[251 | 348.95] loss=1.77 avg=1.64\n",
            "[252 | 350.23] loss=1.67 avg=1.64\n",
            "[253 | 351.50] loss=1.34 avg=1.64\n",
            "[254 | 352.78] loss=1.62 avg=1.64\n",
            "[255 | 354.06] loss=1.59 avg=1.63\n",
            "[256 | 355.33] loss=1.59 avg=1.63\n",
            "[257 | 356.61] loss=1.53 avg=1.63\n",
            "[258 | 357.88] loss=1.60 avg=1.63\n",
            "[259 | 359.16] loss=1.64 avg=1.63\n",
            "[260 | 360.43] loss=1.57 avg=1.63\n",
            "[261 | 361.71] loss=1.55 avg=1.63\n",
            "[262 | 362.98] loss=1.34 avg=1.63\n",
            "[263 | 364.26] loss=1.53 avg=1.63\n",
            "[264 | 365.53] loss=1.50 avg=1.63\n",
            "[265 | 366.81] loss=1.54 avg=1.62\n",
            "[266 | 368.08] loss=1.44 avg=1.62\n",
            "[267 | 369.36] loss=1.68 avg=1.62\n",
            "[268 | 370.64] loss=1.52 avg=1.62\n",
            "[269 | 371.91] loss=1.33 avg=1.62\n",
            "[270 | 373.19] loss=1.50 avg=1.62\n",
            "[271 | 374.46] loss=1.71 avg=1.62\n",
            "[272 | 375.74] loss=1.56 avg=1.62\n",
            "[273 | 377.02] loss=1.47 avg=1.62\n",
            "[274 | 378.29] loss=1.54 avg=1.62\n",
            "[275 | 379.57] loss=1.74 avg=1.62\n",
            "[276 | 380.84] loss=1.26 avg=1.61\n",
            "[277 | 382.12] loss=1.83 avg=1.62\n",
            "[278 | 383.39] loss=1.73 avg=1.62\n",
            "[279 | 384.67] loss=1.46 avg=1.62\n",
            "[280 | 385.94] loss=1.48 avg=1.61\n",
            "[281 | 387.22] loss=1.54 avg=1.61\n",
            "[282 | 388.50] loss=1.60 avg=1.61\n",
            "[283 | 389.77] loss=1.69 avg=1.61\n",
            "[284 | 391.05] loss=1.69 avg=1.61\n",
            "[285 | 392.33] loss=1.57 avg=1.61\n",
            "[286 | 393.61] loss=1.70 avg=1.61\n",
            "[287 | 394.88] loss=1.35 avg=1.61\n",
            "[288 | 396.16] loss=1.59 avg=1.61\n",
            "[289 | 397.44] loss=1.59 avg=1.61\n",
            "[290 | 398.72] loss=1.43 avg=1.61\n",
            "[291 | 400.00] loss=1.86 avg=1.61\n",
            "[292 | 401.27] loss=1.81 avg=1.61\n",
            "[293 | 402.55] loss=1.62 avg=1.61\n",
            "[294 | 403.83] loss=1.56 avg=1.61\n",
            "[295 | 405.10] loss=1.69 avg=1.61\n",
            "[296 | 406.38] loss=1.30 avg=1.61\n",
            "[297 | 407.66] loss=1.55 avg=1.61\n",
            "[298 | 408.94] loss=1.65 avg=1.61\n",
            "[299 | 410.21] loss=1.40 avg=1.61\n",
            "[300 | 411.49] loss=1.58 avg=1.61\n",
            "======== SAMPLE 1 ========\n",
            " the sauce.\n",
            "For each of the following: 1 (1.5 ounce) chopped bacon and 1 (14.5 ounce) chopped basil leaves. Remove slices of sausage from each slice and transfer to a plate. Top each slice with a garnish of white ricotta and a scoop of cheese.\n",
            "For each of the following: 1 (1.5 ounce) chopped bacon and 1 (14.5 ounce) chopped basil leaves. Remove slices of sausage from each slice and transfer to a plate. Top each slice with a garnish of white ricotta and a scoop of cheese. <|endoftext|>\n",
            "eggs vegetable oil grated Parmesan lemon zest salt large eggs coarsely chopped onion finely chopped fresh black pepper extra-virgin olive oil\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 egg \n",
            " 1 tablespoon vegetable oil \n",
            " 1 (8 ounce) grated Parmesan \n",
            " 1 lemon zest (about 6 to 8 ounces), optional \n",
            " 1 pinch salt \n",
            " 1 large eggs, cleaned and dried, plus 1 tablespoon for dressing \n",
            " 2 tablespoons coarsely chopped onion \n",
            " 1/2 teaspoon finely chopped fresh black pepper \n",
            " 1/4 cup extra-virgin olive oil\n",
            "📝Instructions: \n",
            "Preheat oven to 375 degrees F (190 degrees C). Line baking dish with aluminum foil. Heat oil in a heavy skillet over medium-high heat. Put egg in pan. Add mixture to pan. Heat the remaining 3 tablespoons liquid oil in a deep skillet over medium-high heat. Put cheese in the pan. Pour batter into pan. Press mixture back into the pan. Bake 30 to 35 minutes, turning halfway through. Cool in pan, about 5 minutes. Serve the egg with Parmesan mixture.\n",
            "Preheat oven to 375 degrees F (190 degrees C).\n",
            "Line baking dish with aluminum foil. Heat oil in a heavy skillet over medium-high heat. Put egg in pan. Add mixture to pan.\n",
            "Pour batter into pan. Bake 30 to 35 minutes, turning halfway through. Cool in pan, about 5 minutes.\n",
            "Serve the egg with Parmesan mixture. <|endoftext|>\n",
            "all-purpose flour Kosher salt baking soda salt brown sugar white sugar egg all-purpose flour semisweet chocolate chips sugar maple syrup pure vanilla extract vanilla extract butter milk chocolate chips\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 1/8 cups all-purpose flour  \n",
            " Kosher salt  \n",
            " 1 tablespoon baking soda  \n",
            " 1 tsp salt  \n",
            " 1 cup brown sugar  \n",
            " 2 1/2 cups white sugar  \n",
            " 1 egg  \n",
            " 1 1/2 teaspoons all-purpose flour  \n",
            " 2 1/2 teaspoons  \n",
            " 1/4 cup semisweet chocolate chips  \n",
            " 1/2 cup sugar  \n",
            " 1/2 cup maple syrup  \n",
            " 1/2 teaspoon pure vanilla extract  \n",
            " 8 ounces butter  \n",
            " 3/4 cup milk  \n",
            " 4 ounces chocolate chips, or to taste  \n",
            " \n",
            "📝Instructions: \n",
            "For the crust:\n",
            "Whisk together the flour and the baking soda with a pastry blender. Add the oil, and beat well with a fork to blend.\n",
            "Form the dough into a 1/4-inch rectangle, and cut into 6-inch-wide squares. Divide the dough into 2 equally distributed slices. Add the brown sugar, white sugar, egg and flour to the dough, and beat. Transfer to a plate.\n",
            "For the chocolate chip cookies:\n",
            "Spread the butter around 1 rectangle, and pipe the cookies onto cookie sheets. Place the squares onto the greased pan. Bake for 1 to 1 1/2 hours or until golden brown. <|endoftext|>\n",
            "olive oil butter fresh oregano chopped fresh basil leaves sliced onion finely diced shallots large eggs olive oil chopped fresh mushrooms leaves unsalted butter small canola oil chopped fresh basil leaves\n",
            "\n",
            "🥕Ingredients: \n",
            " Olive oil, for frying  \n",
            " 1/3 cup butter  \n",
            " 3/4 lb fresh oregano, finely chopped  \n",
            " 1/4 cup chopped fresh basil leaves  \n",
            " 1/2 cup sliced onion, finely chopped or to taste  \n",
            " 1/4 cup finely diced shallots  \n",
            " 1 large eggs  \n",
            " 1/4 cup olive oil, cooked  \n",
            " 1 cup chopped fresh mushrooms leaves  \n",
            " 2 teaspoons unsalted butter  \n",
            " 1 small canola oil  \n",
            " 1/4 teaspoon chopped fresh basil leaves  \n",
            " \n",
            "📝Instructions: \n",
            "Heat the oil in a 350 degree oven dish.\n",
            "In a bowl, beat the 1/3 cup butter with a fork until stiff, and then gradually whisk in the oregano, oregano, shallot, and vegetables. Season with salt, and add the vegetables to the bowl.\n",
            "Cook the oven and the oven's heat\n",
            "\n",
            "[301 | 424.12] loss=1.56 avg=1.61\n",
            "[302 | 425.39] loss=1.73 avg=1.61\n",
            "[303 | 426.67] loss=1.42 avg=1.61\n",
            "[304 | 427.95] loss=1.63 avg=1.61\n",
            "[305 | 429.22] loss=1.81 avg=1.61\n",
            "[306 | 430.50] loss=1.62 avg=1.61\n",
            "[307 | 431.78] loss=1.57 avg=1.61\n",
            "[308 | 433.05] loss=1.44 avg=1.61\n",
            "[309 | 434.33] loss=1.59 avg=1.61\n",
            "[310 | 435.61] loss=1.29 avg=1.60\n",
            "[311 | 436.88] loss=1.65 avg=1.60\n",
            "[312 | 438.16] loss=1.58 avg=1.60\n",
            "[313 | 439.44] loss=1.42 avg=1.60\n",
            "[314 | 440.71] loss=1.41 avg=1.60\n",
            "[315 | 441.99] loss=1.37 avg=1.60\n",
            "[316 | 443.27] loss=1.58 avg=1.60\n",
            "[317 | 444.54] loss=1.47 avg=1.60\n",
            "[318 | 445.82] loss=1.40 avg=1.59\n",
            "[319 | 447.10] loss=1.39 avg=1.59\n",
            "[320 | 448.37] loss=1.54 avg=1.59\n",
            "[321 | 449.65] loss=1.36 avg=1.59\n",
            "[322 | 450.93] loss=1.68 avg=1.59\n",
            "[323 | 452.20] loss=1.53 avg=1.59\n",
            "[324 | 453.48] loss=1.54 avg=1.59\n",
            "[325 | 454.76] loss=1.44 avg=1.59\n",
            "[326 | 456.03] loss=1.60 avg=1.59\n",
            "[327 | 457.31] loss=1.60 avg=1.59\n",
            "[328 | 458.58] loss=1.80 avg=1.59\n",
            "[329 | 459.86] loss=1.38 avg=1.59\n",
            "[330 | 461.14] loss=1.49 avg=1.59\n",
            "[331 | 462.41] loss=1.54 avg=1.59\n",
            "[332 | 463.69] loss=1.44 avg=1.58\n",
            "[333 | 464.96] loss=1.49 avg=1.58\n",
            "[334 | 466.24] loss=1.70 avg=1.59\n",
            "[335 | 467.52] loss=1.38 avg=1.58\n",
            "[336 | 468.79] loss=1.38 avg=1.58\n",
            "[337 | 470.07] loss=1.37 avg=1.58\n",
            "[338 | 471.34] loss=1.54 avg=1.58\n",
            "[339 | 472.62] loss=1.33 avg=1.58\n",
            "[340 | 473.89] loss=1.45 avg=1.57\n",
            "[341 | 475.17] loss=1.30 avg=1.57\n",
            "[342 | 476.45] loss=1.37 avg=1.57\n",
            "[343 | 477.72] loss=1.45 avg=1.57\n",
            "[344 | 479.00] loss=1.41 avg=1.57\n",
            "[345 | 480.27] loss=1.79 avg=1.57\n",
            "[346 | 481.55] loss=1.57 avg=1.57\n",
            "[347 | 482.82] loss=1.59 avg=1.57\n",
            "[348 | 484.10] loss=1.57 avg=1.57\n",
            "[349 | 485.38] loss=1.57 avg=1.57\n",
            "[350 | 486.65] loss=1.64 avg=1.57\n",
            "[351 | 487.93] loss=1.78 avg=1.57\n",
            "[352 | 489.20] loss=1.56 avg=1.57\n",
            "[353 | 490.48] loss=1.65 avg=1.57\n",
            "[354 | 491.76] loss=1.57 avg=1.57\n",
            "[355 | 493.03] loss=1.49 avg=1.57\n",
            "[356 | 494.31] loss=1.57 avg=1.57\n",
            "[357 | 495.59] loss=1.49 avg=1.57\n",
            "[358 | 496.86] loss=1.62 avg=1.57\n",
            "[359 | 498.14] loss=1.45 avg=1.57\n",
            "[360 | 499.42] loss=1.37 avg=1.57\n",
            "[361 | 500.69] loss=1.43 avg=1.57\n",
            "[362 | 501.97] loss=1.57 avg=1.57\n",
            "[363 | 503.25] loss=1.60 avg=1.57\n",
            "[364 | 504.52] loss=1.39 avg=1.57\n",
            "[365 | 505.80] loss=1.52 avg=1.56\n",
            "[366 | 507.08] loss=1.52 avg=1.56\n",
            "[367 | 508.35] loss=1.61 avg=1.56\n",
            "[368 | 509.63] loss=1.61 avg=1.57\n",
            "[369 | 510.90] loss=1.53 avg=1.57\n",
            "[370 | 512.18] loss=1.56 avg=1.57\n",
            "[371 | 513.46] loss=1.72 avg=1.57\n",
            "[372 | 514.73] loss=1.57 avg=1.57\n",
            "[373 | 516.01] loss=1.44 avg=1.57\n",
            "[374 | 517.28] loss=1.44 avg=1.56\n",
            "[375 | 518.56] loss=1.47 avg=1.56\n",
            "[376 | 519.83] loss=1.48 avg=1.56\n",
            "[377 | 521.11] loss=1.56 avg=1.56\n",
            "[378 | 522.39] loss=1.50 avg=1.56\n",
            "[379 | 523.66] loss=1.75 avg=1.56\n",
            "[380 | 524.94] loss=1.41 avg=1.56\n",
            "[381 | 526.21] loss=1.66 avg=1.56\n",
            "[382 | 527.49] loss=1.47 avg=1.56\n",
            "[383 | 528.76] loss=1.34 avg=1.56\n",
            "[384 | 530.04] loss=1.67 avg=1.56\n",
            "[385 | 531.31] loss=1.56 avg=1.56\n",
            "[386 | 532.59] loss=1.54 avg=1.56\n",
            "[387 | 533.86] loss=1.66 avg=1.56\n",
            "[388 | 535.14] loss=1.59 avg=1.56\n",
            "[389 | 536.42] loss=1.49 avg=1.56\n",
            "[390 | 537.69] loss=1.86 avg=1.56\n",
            "[391 | 538.96] loss=1.50 avg=1.56\n",
            "[392 | 540.24] loss=1.70 avg=1.57\n",
            "[393 | 541.51] loss=1.39 avg=1.56\n",
            "[394 | 542.79] loss=1.65 avg=1.56\n",
            "[395 | 544.07] loss=1.51 avg=1.56\n",
            "[396 | 545.34] loss=1.36 avg=1.56\n",
            "[397 | 546.62] loss=1.62 avg=1.56\n",
            "[398 | 547.89] loss=1.49 avg=1.56\n",
            "[399 | 549.17] loss=1.58 avg=1.56\n",
            "[400 | 550.45] loss=1.84 avg=1.56\n",
            "======== SAMPLE 1 ========\n",
            " Blend  \n",
            " 2 garlic cloves, minced, peeled  \n",
            " 1 tablespoon ground cumin  \n",
            " 2 teaspoons kosher salt  \n",
            " 2 teaspoons ground ginger  \n",
            " 1 teaspoon ground cloves  \n",
            " 2/3 cup butter, melted  \n",
            " 1/4 cup finely chopped fresh flat-leaf parsley  \n",
            " 1 pound fresh bread, cut into 1 inch rounds  \n",
            " 1 teaspoon freshly grated Parmesan  \n",
            " 1/4 teaspoon ground black pepper  \n",
            " 4 large eggs  \n",
            " 1 teaspoon chopped fresh mint  \n",
            " 2 teaspoons dried oregano  \n",
            " \n",
            "📝Instructions: \n",
            "Place garlic, ginger, garlic paste, lemon juice and kosher salt in processor. Process until mixture just holds together. Stir together butter and parsley.\n",
            "Stir ground pepper and baking powder into processor. Beat egg and lemon juice in a bowl. Fold in egg mixture. Add flour, 1/2 teaspoon salt and baking powder. Mix into lemon mixture.\n",
            "Place bread dough into large, shallow bowl and roll in coarse bread crumbs. Press into rounds.\n",
            " <|endoftext|>\n",
            "pepper oil olive grated jalecke sugar large egg cooked couscous - peeled diced jalapeno chiles salt garlic cloves corn tortillas flour tortillas large egg yolks fresh lime juice granulated sugar\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 tablespoon peppercorns, or 2 tablespoons depending on the flavor;  \n",
            " 1 tablespoon olive or 2 tablespoon finely chopped jalecke  \n",
            " 1 tablespoon sugar  \n",
            " 1 large egg cooked couscous, cleaned  \n",
            " 2 fresh jalapeno chiles, peeled, seeded, halved  \n",
            " 1 cup chopped corn tortillas (approximately 2 cups)  \n",
            " 1 3/4 cups flour tortillas, drained  \n",
            " 4 large egg yolks  \n",
            " 1 cup fresh lime juice, plus more if needed  \n",
            " 12 ounces granulated sugar, plus more if needed (not sugar-free if you have a pan)  \n",
            " \n",
            "📝Instructions: \n",
            "Preheat oven to 375 degrees F.\n",
            "Beat peppercorns, sugar, egg together in a bowl until incorporated.\n",
            "Pour egg mixture into flour tortillas.\n",
            "Put couscous in a large bowl. Rub sugar and jalapeno chiles on the bottom, pressing tightly against the back of the baking pan. Add remaining tablespoon of sugar and 1 egg and the flour tortillas and stir, about 5 minutes.\n",
            "Sift together salt and garlic cloves in a medium bowl. Stir together corn tortillas with sugar.\n",
            "Drop batter into flour tortillas; sprinkle tortillas with remaining 3 tablespoons sugar. Bake tortillas until slightly brown on the top, 7 to 10 minutes. The tortillas will thicken up during the baking. Remove any excess honey from the pan. Place some of the caramelized sugar over the sides of the tortillas for garnish.\n",
            " <|endoftext|>\n",
            "flour homemade crepes vanilla chocolate milk lemon vanilla extract fresh blueberries lemon juice all-purpose flour white sugar vanilla extract egg chopped fresh sage leaves salt vanilla extract vanilla bean unsalted butter\n",
            "\n",
            "🥕Ingredients: \n",
            " 6 cups flour, plus more to make topping  \n",
            " 1 cup homemade crepes  \n",
            " 1/4 cup vanilla chocolate milk  \n",
            " 1 cup lemon juice  \n",
            " 1 teaspoon vanilla extract  \n",
            " 2 tablespoons fresh blueberries  \n",
            " 2 teaspoons lemon juice, if using  \n",
            " 2 teaspoons all-purpose flour  \n",
            " 3 tablespoons white sugar, plus more to taste  \n",
            " 1 teaspoon vanilla extract  \n",
            " 3 egg  \n",
            " 2 cups chopped fresh sage leaves  \n",
            " 2 teaspoons salt  \n",
            " 1 teaspoon vanilla extract  \n",
            " 1 cup unsalted butter, room temperature  \n",
            " \n",
            "📝Instructions: \n",
            "Melt flour in a saucepan over medium heat: bring a large saucepan of water to a boil. Place cream cheese and 1 cup milk into the saucepan; place butter on top. Cover with plastic wrap and chill until cool, 10 to 12 hours, stirring and skimming occasionally.\n",
            "Beat chocolate milk, lemon juice, vanilla and flour with a mixer until sugar is evaporated. Add 1 cup water in a slow, steady beat until most of mixture is dissolved. Fold into crepes until evenly blended.\n",
            "Beat cream cheese and lemon juice in a large bowl until peaks form. Divide the mixture among the crepes. Sprinkle with salt. Refrigerate for up to 3 hours.\n",
            " <|endoftext|>\n",
            "large eggs butter eggs vanilla extract baking sheets flour vanilla extract salt cake flour flour baking powder all-purpose flour all-purpose flour all-purpose baking flour all-purpose baking flour all-purpose baking flour white sugar white sugar molasses\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 (8-oz) bag\n",
            "\n",
            "[401 | 563.09] loss=1.75 avg=1.57\n",
            "[402 | 564.37] loss=1.58 avg=1.57\n",
            "[403 | 565.65] loss=1.33 avg=1.56\n",
            "[404 | 566.93] loss=1.65 avg=1.57\n",
            "[405 | 568.20] loss=1.29 avg=1.56\n",
            "[406 | 569.47] loss=1.63 avg=1.56\n",
            "[407 | 570.75] loss=1.72 avg=1.56\n",
            "[408 | 572.02] loss=1.87 avg=1.57\n",
            "[409 | 573.30] loss=1.49 avg=1.57\n",
            "[410 | 574.57] loss=1.44 avg=1.57\n",
            "[411 | 575.84] loss=1.49 avg=1.56\n",
            "[412 | 577.12] loss=1.45 avg=1.56\n",
            "[413 | 578.40] loss=1.34 avg=1.56\n",
            "[414 | 579.67] loss=1.44 avg=1.56\n",
            "[415 | 580.95] loss=1.65 avg=1.56\n",
            "[416 | 582.22] loss=1.37 avg=1.56\n",
            "[417 | 583.50] loss=1.58 avg=1.56\n",
            "[418 | 584.77] loss=1.48 avg=1.56\n",
            "[419 | 586.05] loss=1.54 avg=1.56\n",
            "[420 | 587.33] loss=1.52 avg=1.56\n",
            "[421 | 588.60] loss=1.67 avg=1.56\n",
            "[422 | 589.88] loss=1.48 avg=1.56\n",
            "[423 | 591.15] loss=1.44 avg=1.56\n",
            "[424 | 592.43] loss=1.56 avg=1.56\n",
            "[425 | 593.71] loss=1.60 avg=1.56\n",
            "[426 | 594.98] loss=1.39 avg=1.56\n",
            "[427 | 596.26] loss=1.46 avg=1.55\n",
            "[428 | 597.54] loss=1.63 avg=1.56\n",
            "[429 | 598.81] loss=1.46 avg=1.55\n",
            "[430 | 600.09] loss=1.27 avg=1.55\n",
            "[431 | 601.36] loss=1.55 avg=1.55\n",
            "[432 | 602.64] loss=1.59 avg=1.55\n",
            "[433 | 603.91] loss=1.32 avg=1.55\n",
            "[434 | 605.19] loss=1.29 avg=1.55\n",
            "[435 | 606.46] loss=1.70 avg=1.55\n",
            "[436 | 607.74] loss=1.50 avg=1.55\n",
            "[437 | 609.01] loss=1.62 avg=1.55\n",
            "[438 | 610.29] loss=1.51 avg=1.55\n",
            "[439 | 611.56] loss=1.40 avg=1.55\n",
            "[440 | 612.84] loss=1.74 avg=1.55\n",
            "[441 | 614.11] loss=1.78 avg=1.55\n",
            "[442 | 615.39] loss=1.34 avg=1.55\n",
            "[443 | 616.67] loss=1.65 avg=1.55\n",
            "[444 | 617.94] loss=1.66 avg=1.55\n",
            "[445 | 619.22] loss=1.33 avg=1.55\n",
            "[446 | 620.49] loss=1.55 avg=1.55\n",
            "[447 | 621.77] loss=1.57 avg=1.55\n",
            "[448 | 623.05] loss=1.38 avg=1.55\n",
            "[449 | 624.32] loss=1.42 avg=1.55\n",
            "[450 | 625.60] loss=1.56 avg=1.55\n",
            "[451 | 626.87] loss=1.63 avg=1.55\n",
            "[452 | 628.15] loss=1.66 avg=1.55\n",
            "[453 | 629.42] loss=1.25 avg=1.55\n",
            "[454 | 630.70] loss=1.86 avg=1.55\n",
            "[455 | 631.97] loss=1.24 avg=1.55\n",
            "[456 | 633.25] loss=1.80 avg=1.55\n",
            "[457 | 634.53] loss=1.56 avg=1.55\n",
            "[458 | 635.81] loss=1.47 avg=1.55\n",
            "[459 | 637.09] loss=1.56 avg=1.55\n",
            "[460 | 638.36] loss=1.34 avg=1.55\n",
            "[461 | 639.64] loss=1.30 avg=1.54\n",
            "[462 | 640.92] loss=1.37 avg=1.54\n",
            "[463 | 642.19] loss=1.49 avg=1.54\n",
            "[464 | 643.47] loss=1.57 avg=1.54\n",
            "[465 | 644.75] loss=1.34 avg=1.54\n",
            "[466 | 646.02] loss=1.68 avg=1.54\n",
            "[467 | 647.30] loss=1.41 avg=1.54\n",
            "[468 | 648.57] loss=1.53 avg=1.54\n",
            "[469 | 649.85] loss=1.33 avg=1.54\n",
            "[470 | 651.12] loss=1.26 avg=1.53\n",
            "[471 | 652.40] loss=1.21 avg=1.53\n",
            "[472 | 653.67] loss=1.39 avg=1.53\n",
            "[473 | 654.95] loss=1.54 avg=1.53\n",
            "[474 | 656.22] loss=1.48 avg=1.53\n",
            "[475 | 657.50] loss=1.40 avg=1.53\n",
            "[476 | 658.78] loss=1.71 avg=1.53\n",
            "[477 | 660.05] loss=1.45 avg=1.53\n",
            "[478 | 661.33] loss=1.45 avg=1.53\n",
            "[479 | 662.60] loss=1.52 avg=1.53\n",
            "[480 | 663.88] loss=1.50 avg=1.53\n",
            "[481 | 665.16] loss=1.57 avg=1.53\n",
            "[482 | 666.43] loss=1.53 avg=1.53\n",
            "[483 | 667.71] loss=1.68 avg=1.53\n",
            "[484 | 668.98] loss=1.57 avg=1.53\n",
            "[485 | 670.25] loss=1.65 avg=1.53\n",
            "[486 | 671.53] loss=1.36 avg=1.53\n",
            "[487 | 672.81] loss=1.30 avg=1.53\n",
            "[488 | 674.08] loss=1.31 avg=1.52\n",
            "[489 | 675.36] loss=1.51 avg=1.52\n",
            "[490 | 676.63] loss=1.45 avg=1.52\n",
            "[491 | 677.91] loss=1.43 avg=1.52\n",
            "[492 | 679.18] loss=1.57 avg=1.52\n",
            "[493 | 680.46] loss=1.58 avg=1.52\n",
            "[494 | 681.74] loss=1.72 avg=1.53\n",
            "[495 | 683.01] loss=1.43 avg=1.52\n",
            "[496 | 684.29] loss=1.37 avg=1.52\n",
            "[497 | 685.56] loss=1.38 avg=1.52\n",
            "[498 | 686.84] loss=1.47 avg=1.52\n",
            "[499 | 688.11] loss=1.73 avg=1.52\n",
            "[500 | 689.39] loss=1.54 avg=1.52\n",
            "======== SAMPLE 1 ========\n",
            ") and water in a large skillet with a slotted spoon; reduce heat to medium and cook over medium-low heat until the butter is melted, about 2 minutes. Stir in flour to a food processor and pulse until mixture is smooth. Add the oil to a large pot over medium heat and bring to a boil; whisk occasionally, shaking off excess oil. Continue whisking until the batter is evenly coated with batter, about 3 minutes. Transfer the batter to a serving platter.\n",
            "Serve hot or at room temperature with chive de cassis.\n",
            "Serve with hot or at room temperature with chives. <|endoftext|>\n",
            "olive oil minced garlic can water vegetable oil chopped black pepper cloves garlic chicken stock or rice cereal small yellow onion cloves garlic red wine vinegar cayenne pepper\n",
            "\n",
            "🥕Ingredients: \n",
            " 2 tablespoons olive oil \n",
            " 1/4 cup minced garlic \n",
            " 1/2 cup can water \n",
            " 2 tablespoons vegetable oil, divided \n",
            " 4 teaspoons chopped black pepper \n",
            " 4 cloves garlic, minced \n",
            " 1 cup chicken stock or rice cereal \n",
            " 1 small yellow onion, thinly sliced \n",
            " 4 cloves garlic, minced \n",
            " 1 1/2 teaspoons red wine vinegar \n",
            " 1/2 teaspoon cayenne pepper, cut into 1/2-inch pieces\n",
            "📝Instructions: \n",
            "Heat the olive oil in a large skillet over medium heat. Add half of the roasted pork, the rice, chicken stock, onion, garlic, vinegar and 1/2 cup of the chicken stock. Cover and cook for 5 minutes, or until pork is tender.\n",
            "Add the rice to the skillet and bring to a boil. Reduce the heat to low, cover and simmer 1 minute. Simmer until rice is slightly tender but still firm, remove from the heat, cool and chop.\n",
            "Meanwhile, sift the vegetable oil through a fine-mesh sieve or large spoon into a mixing bowl. Add 1 cup of the roasted pork and a tablespoon of the chopped black pepper and mix well, then set aside.\n",
            "While the sauce is cooking, combine the cornmeal, cayenne pepper and 1/2 cup of the cornmeal and toss well to coat. Heat the water in a deep saucepan over medium-high heat. Add the remaining chicken stock and continue to simmer until the filling is thick and the sauce thickens, about 5 minutes.\n",
            "Serve the sauce over the top of a serving plate or a bed of brown rice. <|endoftext|>\n",
            "vegetable oil boneless chicken breasts Salt and freshly ground black pepper to taste package frozen spinach egg white butter chopped fresh cilantro leaves\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 tablespoon vegetable oil, plus more for roasting pan \n",
            " 3/4 pound boneless chicken breasts, split \n",
            " Salt and freshly ground black pepper to taste \n",
            " 1 (28-ounce) package frozen spinach \n",
            " 2 egg white \n",
            " 2 tablespoons butter \n",
            " 3 tablespoons chopped fresh cilantro leaves\n",
            "📝Instructions: \n",
            "Heat oil in a large skillet over medium heat. Saute chickens until golden brown, 8 to 10 minutes. Remove from pan. Add spinach to pan and toss gently with egg white. Repeat with remaining spinach.\n",
            "Heat butter in same skillet over medium heat. Sift eggs with reserved butter. Reduce heat to medium-low and cook until golden brown, about 2 minutes. Stir in cilantro leaves. Garnish with cilantro wedges. <|endoftext|>\n",
            "ground allspice salt and pepper to taste citrus milk milk plain yogurt lemon juice\n",
            "\n",
            "🥕Ingredients: \n",
            " enough ground allspice \n",
            " salt and pepper to taste \n",
            " 1 1/2 cups creamy peanut butter \n",
            " 1 1/2 cups milk \n",
            " 2 tablespoons plain yogurt \n",
            " 1 teaspoon lemon juice\n",
            "📝Instructions: \n",
            "Warm ground allspice in a 2-quart saucepan over medium-high heat. Sprinkle peanut butter over the peanut butter and swirl until melted, 4 to 5 minutes. Add peanut and yogurt, lemon juice, 1/2 cup melted butter and milk. Mix until just combined. Taste and adjust seasoning according to taste. Add yogurt. <|endoftext|>\n",
            "olive oil large onion large shrimp fillets Kosher salt and freshly ground black pepper minced pecorino or chorizo or extra-virgin olive oil grated Vidalia Romano cheese\n",
            "\n",
            "🥕Ingredients: \n",
            " 1/2 tablespoon olive oil \n",
            " 1 pound large onion, diced \n",
            " 1 pound large shrimp fillets \n",
            " Kosher salt and freshly ground black pepper \n",
            " 1/4 teaspoon minced pecorino or chorizo or extra-virgin olive oil \n",
            " 3 tablespoons grated Vidalia Romano cheese\n",
            "📝Instructions: \n",
            "Watch how to make this recipe.\n",
            "Heat the oil to medium-high and saute onion, shrimp and fil\n",
            "\n",
            "[501 | 702.05] loss=1.81 avg=1.53\n",
            "[502 | 703.32] loss=1.56 avg=1.53\n",
            "[503 | 704.60] loss=1.45 avg=1.53\n",
            "[504 | 705.87] loss=1.54 avg=1.53\n",
            "[505 | 707.15] loss=1.44 avg=1.53\n",
            "[506 | 708.42] loss=1.77 avg=1.53\n",
            "[507 | 709.70] loss=1.73 avg=1.53\n",
            "[508 | 710.97] loss=1.57 avg=1.53\n",
            "[509 | 712.25] loss=1.53 avg=1.53\n",
            "[510 | 713.52] loss=1.43 avg=1.53\n",
            "[511 | 714.80] loss=1.57 avg=1.53\n",
            "[512 | 716.07] loss=1.47 avg=1.53\n",
            "[513 | 717.35] loss=1.31 avg=1.53\n",
            "[514 | 718.62] loss=1.58 avg=1.53\n",
            "[515 | 719.90] loss=1.47 avg=1.53\n",
            "[516 | 721.17] loss=1.32 avg=1.52\n",
            "[517 | 722.45] loss=1.45 avg=1.52\n",
            "[518 | 723.72] loss=1.76 avg=1.53\n",
            "[519 | 725.00] loss=1.48 avg=1.53\n",
            "[520 | 726.27] loss=1.30 avg=1.52\n",
            "[521 | 727.55] loss=1.47 avg=1.52\n",
            "[522 | 728.83] loss=1.44 avg=1.52\n",
            "[523 | 730.10] loss=1.68 avg=1.52\n",
            "[524 | 731.37] loss=1.39 avg=1.52\n",
            "[525 | 732.65] loss=1.52 avg=1.52\n",
            "[526 | 733.93] loss=1.59 avg=1.52\n",
            "[527 | 735.20] loss=1.47 avg=1.52\n",
            "[528 | 736.48] loss=1.60 avg=1.52\n",
            "[529 | 737.75] loss=1.29 avg=1.52\n",
            "[530 | 739.03] loss=1.58 avg=1.52\n",
            "[531 | 740.31] loss=1.57 avg=1.52\n",
            "[532 | 741.58] loss=1.61 avg=1.52\n",
            "[533 | 742.86] loss=1.41 avg=1.52\n",
            "[534 | 744.13] loss=1.32 avg=1.52\n",
            "[535 | 745.41] loss=1.87 avg=1.52\n",
            "[536 | 746.68] loss=1.62 avg=1.52\n",
            "[537 | 747.96] loss=1.37 avg=1.52\n",
            "[538 | 749.23] loss=1.24 avg=1.52\n",
            "[539 | 750.51] loss=1.55 avg=1.52\n",
            "[540 | 751.78] loss=1.25 avg=1.52\n",
            "[541 | 753.06] loss=1.47 avg=1.52\n",
            "[542 | 754.33] loss=1.43 avg=1.52\n",
            "[543 | 755.61] loss=1.53 avg=1.52\n",
            "[544 | 756.88] loss=1.37 avg=1.51\n",
            "[545 | 758.16] loss=1.53 avg=1.52\n",
            "[546 | 759.43] loss=1.47 avg=1.51\n",
            "[547 | 760.71] loss=1.76 avg=1.52\n",
            "[548 | 761.98] loss=1.33 avg=1.52\n",
            "[549 | 763.26] loss=1.40 avg=1.51\n",
            "[550 | 764.54] loss=1.49 avg=1.51\n",
            "[551 | 765.81] loss=1.21 avg=1.51\n",
            "[552 | 767.09] loss=1.47 avg=1.51\n",
            "[553 | 768.36] loss=1.54 avg=1.51\n",
            "[554 | 769.63] loss=1.30 avg=1.51\n",
            "[555 | 770.91] loss=1.44 avg=1.51\n",
            "[556 | 772.19] loss=1.48 avg=1.51\n",
            "[557 | 773.46] loss=1.28 avg=1.51\n",
            "[558 | 774.73] loss=1.22 avg=1.50\n",
            "[559 | 776.01] loss=1.71 avg=1.50\n",
            "[560 | 777.28] loss=1.49 avg=1.50\n",
            "[561 | 778.56] loss=1.44 avg=1.50\n",
            "[562 | 779.83] loss=1.43 avg=1.50\n",
            "[563 | 781.11] loss=1.31 avg=1.50\n",
            "[564 | 782.38] loss=1.56 avg=1.50\n",
            "[565 | 783.66] loss=1.42 avg=1.50\n",
            "[566 | 784.94] loss=1.35 avg=1.50\n",
            "[567 | 786.21] loss=1.55 avg=1.50\n",
            "[568 | 787.49] loss=1.50 avg=1.50\n",
            "[569 | 788.76] loss=1.50 avg=1.50\n",
            "[570 | 790.04] loss=1.40 avg=1.50\n",
            "[571 | 791.31] loss=1.43 avg=1.50\n",
            "[572 | 792.59] loss=1.51 avg=1.50\n",
            "[573 | 793.86] loss=1.57 avg=1.50\n",
            "[574 | 795.14] loss=1.45 avg=1.50\n",
            "[575 | 796.41] loss=1.26 avg=1.50\n",
            "[576 | 797.69] loss=1.68 avg=1.50\n",
            "[577 | 798.97] loss=1.44 avg=1.50\n",
            "[578 | 800.24] loss=1.71 avg=1.50\n",
            "[579 | 801.52] loss=1.54 avg=1.50\n",
            "[580 | 802.79] loss=1.51 avg=1.50\n",
            "[581 | 804.07] loss=1.44 avg=1.50\n",
            "[582 | 805.35] loss=1.51 avg=1.50\n",
            "[583 | 806.62] loss=1.56 avg=1.50\n",
            "[584 | 807.90] loss=1.55 avg=1.50\n",
            "[585 | 809.17] loss=1.32 avg=1.50\n",
            "[586 | 810.45] loss=1.58 avg=1.50\n",
            "[587 | 811.73] loss=1.53 avg=1.50\n",
            "[588 | 813.00] loss=1.29 avg=1.50\n",
            "[589 | 814.28] loss=1.36 avg=1.50\n",
            "[590 | 815.55] loss=1.75 avg=1.50\n",
            "[591 | 816.83] loss=1.51 avg=1.50\n",
            "[592 | 818.10] loss=1.44 avg=1.50\n",
            "[593 | 819.38] loss=1.50 avg=1.50\n",
            "[594 | 820.65] loss=1.89 avg=1.50\n",
            "[595 | 821.93] loss=1.47 avg=1.50\n",
            "[596 | 823.21] loss=1.62 avg=1.50\n",
            "[597 | 824.48] loss=1.57 avg=1.50\n",
            "[598 | 825.76] loss=1.18 avg=1.50\n",
            "[599 | 827.04] loss=1.64 avg=1.50\n",
            "[600 | 828.31] loss=1.37 avg=1.50\n",
            "======== SAMPLE 1 ========\n",
            " olive.\n",
            "Muddle hot water from shrimp with reserved green onion and set aside. Drizzle extra-virgin olive oil over shrimp.\n",
            "To serve: Spoon warm pasta and garlic into bowls. Sprinkle with black pepper.\n",
            " <|endoftext|>\n",
            "quinoa water unsweetened coconut flour salt\n",
            "\n",
            "🥕Ingredients: \n",
            " 1/2 cup quinoa  \n",
            " 3 tablespoons water  \n",
            " 2 tablespoons (1 liter) unsweetened coconut flour  \n",
            " 1/2 teaspoon salt  \n",
            " \n",
            "📝Instructions: \n",
            "Place quinoa in a small bowl and stir with coconut flour until well blended. Set aside.\n",
            "Whisk together water, water, and 1 tablespoon coconut flour until blended.\n",
            "Add quinoa and water; whisk until combined. Fold in coconut flakes.\n",
            " <|endoftext|>\n",
            "olive oil sliced ginger medium red onion cloves garlic yellow onion red bell pepper green bell pepper red bell pepper red/yellow chili salt ground black pepper vegetable oil chopped sweet peas dry sesame oil\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 tablespoon olive oil, plus additional for frying  \n",
            " 4/5 to 6 slices ginger  \n",
            " 1 medium red onion, sliced  \n",
            " 8 cloves garlic, peeled, sliced lengthwise  \n",
            " 10 yellow onion, sliced  \n",
            " 2 red bell pepper, sliced  \n",
            " 1 green bell pepper, sliced  \n",
            " 1/2 red/yellow chili, chopped  \n",
            " 1/2 teaspoon salt  \n",
            " ground black pepper, plus more for garnish  \n",
            " 1/2 cup vegetable oil  \n",
            " 2 tablespoons chopped sweet peas  \n",
            " 1/2 cup dry sesame oil  \n",
            " \n",
            "📝Instructions: \n",
            "Heat oil in a skillet over medium-high heat; saute until slightly shimmery. Add ginger and onion; saute until onion turns soft. Add garlic, green onion, red pepper, green bell pepper, red chili and salt; stir until garlic and green onions are fragrant.\n",
            " <|endoftext|>\n",
            "bacon dry white wine vinegar sliced green onions slices dry white wine ground dried tomatoes bay leaves\n",
            "\n",
            "🥕Ingredients: \n",
            " 3/4 cup bacon  \n",
            " 1 1/3 cups dry white wine vinegar  \n",
            " 2 to 3/4 cups sliced green onions  \n",
            " 8 slices dry white wine  \n",
            " 3 teaspoons ground dried tomatoes  \n",
            " 2 bay leaves  \n",
            " \n",
            "📝Instructions: \n",
            "Preheat a grill pan to medium.\n",
            "Brown the bacon and 1 1/3 cups of the bacon fat on the middle, pressing the fat on the bacon to coat. Tear the bacon and set aside.\n",
            "Add the dried green onions to the skillet and saute them until lightly browned.\n",
            "In a separate saucepan over medium heat, add the ground beef. Cover and cook over medium-high heat, uncovered, until the bacon mixture has melted and the beef is tender. Set aside.\n",
            "Prepare a large skillet over medium high heat.\n",
            "Slice the meat into 8 slices. Place on a cutting board and fry until the meat is almost browned and the fat is melted and smooth, about 3 minutes. Remove the slices and drain.\n",
            " <|endoftext|>\n",
            "cooking spray package mini muffin cups or plain muffin size mini cake mix baking soda all purpose flour egg yolks salt ground cinnamon sugar egg whites all-purpose flour\n",
            "\n",
            "🥕Ingredients: \n",
            " cooking spray  \n",
            " 2 (6 ounce) package mini muffin cups or plain muffin size  \n",
            " 1/4 cup baking soda  \n",
            " 1/4 cup all purpose flour  \n",
            " 8 egg yolks, beaten  \n",
            " 1/4 teaspoon salt  \n",
            " 1 teaspoon ground cinnamon  \n",
            " 4 ounces sugar  \n",
            " 3 egg whites  \n",
            " 4 tablespoons all-purpose flour  \n",
            " \n",
            "📝Instructions: \n",
            "Heat cooking spray. Put an oven rack in the middle position and preheat the oven to 400 degrees F.\n",
            "In large bowl, whisk together baking soda, baking powder, 1 1/2 tablespoons of the egg yolks, salt and 1 teaspoon of cinnamon. Shape batter into a well and place on the bottom 2 inches off the griddle.\n",
            "Bake in preheated oven until edges are golden and puffed up with bubbles, 8 to 12 minutes.\n",
            "Stir in 3 to 5 tablespoons of the egg whites. Bake 3 to 4 minutes and let stand until a smooth, glossy finish. Cool in the pans on a wire rack for 10 minutes.\n",
            "Serve warm.\n",
            " <|endoftext|>\n",
            "vegetable oil all-purpose flour unsweetened coconut oil salt garlic cloves can frozen peas water sugar coconut oil coconut milk\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 tablespoon vegetable oil  \n",
            " 2 1/2 tablespoons\n",
            "\n",
            "[601 | 840.89] loss=1.48 avg=1.50\n",
            "[602 | 842.17] loss=1.60 avg=1.50\n",
            "[603 | 843.45] loss=1.62 avg=1.50\n",
            "[604 | 844.72] loss=1.46 avg=1.50\n",
            "[605 | 846.00] loss=1.48 avg=1.50\n",
            "[606 | 847.28] loss=1.67 avg=1.50\n",
            "[607 | 848.55] loss=1.64 avg=1.51\n",
            "[608 | 849.83] loss=1.50 avg=1.50\n",
            "[609 | 851.10] loss=1.55 avg=1.51\n",
            "[610 | 852.38] loss=1.39 avg=1.50\n",
            "[611 | 853.65] loss=1.54 avg=1.50\n",
            "[612 | 854.93] loss=1.47 avg=1.50\n",
            "[613 | 856.20] loss=1.70 avg=1.51\n",
            "[614 | 857.48] loss=1.28 avg=1.50\n",
            "[615 | 858.75] loss=1.60 avg=1.50\n",
            "[616 | 860.03] loss=1.25 avg=1.50\n",
            "[617 | 861.31] loss=1.58 avg=1.50\n",
            "[618 | 862.58] loss=1.76 avg=1.51\n",
            "[619 | 863.86] loss=1.44 avg=1.50\n",
            "[620 | 865.14] loss=1.48 avg=1.50\n",
            "[621 | 866.41] loss=1.34 avg=1.50\n",
            "[622 | 867.69] loss=1.35 avg=1.50\n",
            "[623 | 868.96] loss=1.40 avg=1.50\n",
            "[624 | 870.24] loss=1.51 avg=1.50\n",
            "[625 | 871.51] loss=1.59 avg=1.50\n",
            "[626 | 872.79] loss=1.38 avg=1.50\n",
            "[627 | 874.07] loss=1.37 avg=1.50\n",
            "[628 | 875.34] loss=1.77 avg=1.50\n",
            "[629 | 876.62] loss=1.65 avg=1.50\n",
            "[630 | 877.89] loss=1.59 avg=1.50\n",
            "[631 | 879.17] loss=1.50 avg=1.50\n",
            "[632 | 880.44] loss=1.57 avg=1.50\n",
            "[633 | 881.72] loss=1.28 avg=1.50\n",
            "[634 | 882.99] loss=1.81 avg=1.51\n",
            "[635 | 884.27] loss=1.55 avg=1.51\n",
            "[636 | 885.55] loss=1.27 avg=1.50\n",
            "[637 | 886.82] loss=1.49 avg=1.50\n",
            "[638 | 888.10] loss=1.34 avg=1.50\n",
            "[639 | 889.37] loss=1.41 avg=1.50\n",
            "[640 | 890.65] loss=1.35 avg=1.50\n",
            "[641 | 891.92] loss=1.30 avg=1.50\n",
            "[642 | 893.20] loss=1.63 avg=1.50\n",
            "[643 | 894.47] loss=1.74 avg=1.50\n",
            "[644 | 895.75] loss=1.69 avg=1.50\n",
            "[645 | 897.03] loss=1.55 avg=1.50\n",
            "[646 | 898.30] loss=1.49 avg=1.50\n",
            "[647 | 899.58] loss=1.56 avg=1.50\n",
            "[648 | 900.85] loss=1.32 avg=1.50\n",
            "[649 | 902.13] loss=1.49 avg=1.50\n",
            "[650 | 903.41] loss=1.61 avg=1.50\n",
            "[651 | 904.68] loss=1.33 avg=1.50\n",
            "[652 | 905.96] loss=1.44 avg=1.50\n",
            "[653 | 907.23] loss=1.63 avg=1.50\n",
            "[654 | 908.51] loss=1.32 avg=1.50\n",
            "[655 | 909.79] loss=1.32 avg=1.50\n",
            "[656 | 911.06] loss=1.43 avg=1.50\n",
            "[657 | 912.33] loss=1.62 avg=1.50\n",
            "[658 | 913.61] loss=1.30 avg=1.50\n",
            "[659 | 914.89] loss=1.39 avg=1.50\n",
            "[660 | 916.16] loss=1.57 avg=1.50\n",
            "[661 | 917.44] loss=1.59 avg=1.50\n",
            "[662 | 918.71] loss=1.44 avg=1.50\n",
            "[663 | 919.99] loss=1.40 avg=1.50\n",
            "[664 | 921.26] loss=1.76 avg=1.50\n",
            "[665 | 922.54] loss=1.68 avg=1.50\n",
            "[666 | 923.81] loss=1.41 avg=1.50\n",
            "[667 | 925.09] loss=1.61 avg=1.50\n",
            "[668 | 926.36] loss=1.60 avg=1.50\n",
            "[669 | 927.64] loss=1.47 avg=1.50\n",
            "[670 | 928.91] loss=1.40 avg=1.50\n",
            "[671 | 930.19] loss=1.30 avg=1.50\n",
            "[672 | 931.47] loss=1.49 avg=1.50\n",
            "[673 | 932.74] loss=1.34 avg=1.50\n",
            "[674 | 934.02] loss=1.54 avg=1.50\n",
            "[675 | 935.29] loss=1.65 avg=1.50\n",
            "[676 | 936.57] loss=1.23 avg=1.50\n",
            "[677 | 937.84] loss=1.44 avg=1.50\n",
            "[678 | 939.12] loss=1.39 avg=1.49\n",
            "[679 | 940.39] loss=1.51 avg=1.49\n",
            "[680 | 941.67] loss=1.82 avg=1.50\n",
            "[681 | 942.95] loss=1.49 avg=1.50\n",
            "[682 | 944.23] loss=1.23 avg=1.49\n",
            "[683 | 945.51] loss=1.58 avg=1.50\n",
            "[684 | 946.79] loss=1.52 avg=1.50\n",
            "[685 | 948.06] loss=1.82 avg=1.50\n",
            "[686 | 949.34] loss=1.37 avg=1.50\n",
            "[687 | 950.62] loss=1.27 avg=1.50\n",
            "[688 | 951.89] loss=1.56 avg=1.50\n",
            "[689 | 953.17] loss=1.54 avg=1.50\n",
            "[690 | 954.45] loss=1.38 avg=1.50\n",
            "[691 | 955.72] loss=1.34 avg=1.49\n",
            "[692 | 957.00] loss=1.28 avg=1.49\n",
            "[693 | 958.27] loss=1.49 avg=1.49\n",
            "[694 | 959.55] loss=1.51 avg=1.49\n",
            "[695 | 960.82] loss=1.60 avg=1.49\n",
            "[696 | 962.10] loss=1.42 avg=1.49\n",
            "[697 | 963.37] loss=1.33 avg=1.49\n",
            "[698 | 964.65] loss=1.77 avg=1.49\n",
            "[699 | 965.93] loss=1.51 avg=1.49\n",
            "[700 | 967.20] loss=1.51 avg=1.49\n",
            "======== SAMPLE 1 ========\n",
            " egg garlic powder onion powder chopped fresh parsley \n",
            " 2 tablespoons olive oil, preferably olive\n",
            "📝Instructions: \n",
            "Bring a large pot of barely simmering water to a boil. Reduce heat and simmer over low heat, covered, until tender, about 20 minutes. Drain.\n",
            "In a bowl, toss the beef with the garlic powder, onion powder, and 1 tablespoon of the oil. Add the parsley, season the chicken with salt and pepper, and toss to coat.\n",
            "Toss the chicken in the flour mixture and cook until done. Flip the chicken and cook until a smooth, golden brown on the other side. Add the garlic powder mixture and the onion and cook, stirring constantly, until the butter is melted. Add the salt and pepper and cook until the mixture becomes thick enough to coat the chicken breasts, not just opaque and bubbling. Add more salt and pepper to taste if the broth is not strong enough.\n",
            "Transfer the beef or chicken mixture to a large serving pan and toss to coat. Chill over covered overnight.\n",
            "Preheat the oven to 350 degrees F.\n",
            "For the chicken: Heat the olive oil in a skillet over medium-high heat. When the oil is hot, add the chicken, garlic, and onion; cook, stirring to combine (slightly reduce the heat), until the onions are charred, about 5 minutes. Add the broth, cook, stirring just to combine the flavors, and transfer to the same skillet over medium heat. Stir the eggs, butter, salt, and pepper, and cook until the eggs are heated through, about 10 minutes. Divide among 6 large serving plates and sprinkle with the chicken mixture. <|endoftext|>\n",
            "packages cream cheese can pumpkin puree can pumpkin pie filling (such as Bob's Old Fashioned®) cream of chicken whole milk milk eggs baking powder salt eggs\n",
            "\n",
            "🥕Ingredients: \n",
            " 12 (8-ounce) packages cream cheese, softened \n",
            " 1 (8-ounce) can pumpkin puree \n",
            " 2 cups can pumpkin pie filling (such as Bob's Old Fashioned®) \n",
            " 1 (8-ounce) cream of chicken \n",
            " 1/3 cup milk \n",
            " 1 egg \n",
            " 1/2 teaspoon baking powder \n",
            " 1/2 teaspoon salt \n",
            " 4 eggs\n",
            "📝Instructions: \n",
            "Preheat oven to 350 degrees F. In a medium bowl, combine cream cheese, pumpkin pie filling, cream of chicken, milk, egg, and salt and combine into the cheese mixture. Spoon mixture into a 6-count bag, and seal. Drizzle cream in another 6-count bag, and roll into a rectangular round disk, with edges closed. Wrap disk in foil and refrigerate for 2 hours; let stand overnight.\n",
            "Heat oven to 425 degrees F. Grease a 12-inch nonstick baking pan. On a lightly floured work surface, dust with flour, and spread out 1 1/2 inch pieces of dough on baking pans. On a lightly floured work surface, roll each pastry disk lightly to adhere. Brush filling with flour until evenly moist, about 3 minutes. Arrange dough in center of crust of baking pan, and sprinkle with baking powder. Brush remaining dough with flour mixture. Bake crust until golden and golden brown on an oiled cookie sheet, about 8 minutes. Flip. Let crust set. Cut 1 1/2 inch squares on ungreased cookie sheet, and wrap in plastic wrap to keep warm.\n",
            "Toast dough in a double boiler in the top third of a preheated 300 degree oven until golden brown. Transfer dough to parchment paper or foil and let cookies cool 30 minutes. Transfer oven rack to a cool place and place 2 cookies on a baking sheet lined with wax paper. Bake at 350 degrees F directly over the broiler setting. Let cookies cool in the preheated oven; sprinkle with cinnamon.\n",
            "Preheat oven to 400 degrees F. Bake until crispy all over, and cookies are no longer pink when lightly press-tender, about 6 minutes on each side. Cool cookies completely. Cut into 9 inch slices, and garnish with cinnamon slices if desired. <|endoftext|>\n",
            "-pound casserole with sauce small onion diced red bell pepper diced sweet onion cooked cooked beef roast turkey\n",
            "\n",
            "🥕Ingredients: \n",
            " One 7-pound casserole with sauce \n",
            " 1 small onion, thinly sliced \n",
            " 1 diced red bell pepper \n",
            " 4 diced sweet onion \n",
            " 2 to 3 cups cooked cooked beef roast \n",
            " 1/2 pound turkey\n",
            "📝Instructions: \n",
            "Preheat oven to 350 degrees.\n",
            "In a large stockpot using 2 inches water over medium-high heat, bring 3-4 quarts water to a boil and reduce heat to low. Add water and cook, stirring often, until water is no longer pink under the skin, about 25 minutes. Drain and cool.\n",
            "In a large saucepan over medium heat, pour 3-4 quarts water\n",
            "\n",
            "[701 | 979.78] loss=1.38 avg=1.49\n",
            "[702 | 981.06] loss=1.40 avg=1.49\n",
            "[703 | 982.34] loss=1.42 avg=1.49\n",
            "[704 | 983.61] loss=1.53 avg=1.49\n",
            "[705 | 984.89] loss=1.41 avg=1.49\n",
            "[706 | 986.16] loss=1.33 avg=1.49\n",
            "[707 | 987.44] loss=1.39 avg=1.49\n",
            "[708 | 988.72] loss=1.40 avg=1.49\n",
            "[709 | 989.99] loss=1.48 avg=1.49\n",
            "[710 | 991.27] loss=1.33 avg=1.49\n",
            "[711 | 992.54] loss=1.40 avg=1.48\n",
            "[712 | 993.82] loss=1.39 avg=1.48\n",
            "[713 | 995.09] loss=1.27 avg=1.48\n",
            "[714 | 996.37] loss=1.35 avg=1.48\n",
            "[715 | 997.64] loss=1.55 avg=1.48\n",
            "[716 | 998.92] loss=1.46 avg=1.48\n",
            "[717 | 1000.19] loss=1.42 avg=1.48\n",
            "[718 | 1001.47] loss=1.37 avg=1.48\n",
            "[719 | 1002.74] loss=1.40 avg=1.48\n",
            "[720 | 1004.02] loss=1.59 avg=1.48\n",
            "[721 | 1005.29] loss=1.43 avg=1.48\n",
            "[722 | 1006.57] loss=1.67 avg=1.48\n",
            "[723 | 1007.84] loss=1.81 avg=1.48\n",
            "[724 | 1009.12] loss=1.43 avg=1.48\n",
            "[725 | 1010.39] loss=1.49 avg=1.48\n",
            "[726 | 1011.67] loss=1.38 avg=1.48\n",
            "[727 | 1012.94] loss=1.85 avg=1.49\n",
            "[728 | 1014.22] loss=1.65 avg=1.49\n",
            "[729 | 1015.50] loss=1.40 avg=1.49\n",
            "[730 | 1016.77] loss=1.43 avg=1.49\n",
            "[731 | 1018.05] loss=1.29 avg=1.48\n",
            "[732 | 1019.33] loss=1.22 avg=1.48\n",
            "[733 | 1020.60] loss=1.51 avg=1.48\n",
            "[734 | 1021.88] loss=1.33 avg=1.48\n",
            "[735 | 1023.15] loss=1.34 avg=1.48\n",
            "[736 | 1024.43] loss=1.51 avg=1.48\n",
            "[737 | 1025.70] loss=1.50 avg=1.48\n",
            "[738 | 1026.98] loss=1.33 avg=1.48\n",
            "[739 | 1028.25] loss=1.35 avg=1.48\n",
            "[740 | 1029.53] loss=1.58 avg=1.48\n",
            "[741 | 1030.80] loss=1.60 avg=1.48\n",
            "[742 | 1032.07] loss=1.28 avg=1.48\n",
            "[743 | 1033.35] loss=1.41 avg=1.48\n",
            "[744 | 1034.62] loss=1.71 avg=1.48\n",
            "[745 | 1035.90] loss=1.44 avg=1.48\n",
            "[746 | 1037.17] loss=1.38 avg=1.48\n",
            "[747 | 1038.45] loss=1.53 avg=1.48\n",
            "[748 | 1039.72] loss=1.32 avg=1.48\n",
            "[749 | 1041.00] loss=1.28 avg=1.47\n",
            "[750 | 1042.27] loss=1.34 avg=1.47\n",
            "[751 | 1043.55] loss=1.25 avg=1.47\n",
            "[752 | 1044.82] loss=1.26 avg=1.47\n",
            "[753 | 1046.10] loss=1.46 avg=1.47\n",
            "[754 | 1047.37] loss=1.69 avg=1.47\n",
            "[755 | 1048.65] loss=1.60 avg=1.47\n",
            "[756 | 1049.92] loss=1.50 avg=1.47\n",
            "[757 | 1051.20] loss=1.51 avg=1.47\n",
            "[758 | 1052.47] loss=1.48 avg=1.47\n",
            "[759 | 1053.75] loss=1.27 avg=1.47\n",
            "[760 | 1055.02] loss=1.68 avg=1.47\n",
            "[761 | 1056.30] loss=1.39 avg=1.47\n",
            "[762 | 1057.57] loss=1.73 avg=1.47\n",
            "[763 | 1058.85] loss=1.42 avg=1.47\n",
            "[764 | 1060.12] loss=1.29 avg=1.47\n",
            "[765 | 1061.40] loss=1.47 avg=1.47\n",
            "[766 | 1062.68] loss=1.39 avg=1.47\n",
            "[767 | 1063.95] loss=1.41 avg=1.47\n",
            "[768 | 1065.23] loss=1.45 avg=1.47\n",
            "[769 | 1066.50] loss=1.66 avg=1.47\n",
            "[770 | 1067.78] loss=1.57 avg=1.47\n",
            "[771 | 1069.05] loss=1.68 avg=1.48\n",
            "[772 | 1070.33] loss=1.42 avg=1.48\n",
            "[773 | 1071.60] loss=1.42 avg=1.47\n",
            "[774 | 1072.87] loss=1.36 avg=1.47\n",
            "[775 | 1074.15] loss=1.57 avg=1.47\n",
            "[776 | 1075.42] loss=1.60 avg=1.48\n",
            "[777 | 1076.70] loss=1.49 avg=1.48\n",
            "[778 | 1077.97] loss=1.51 avg=1.48\n",
            "[779 | 1079.25] loss=1.17 avg=1.47\n",
            "[780 | 1080.52] loss=1.33 avg=1.47\n",
            "[781 | 1081.79] loss=1.39 avg=1.47\n",
            "[782 | 1083.07] loss=1.34 avg=1.47\n",
            "[783 | 1084.34] loss=1.47 avg=1.47\n",
            "[784 | 1085.62] loss=1.71 avg=1.47\n",
            "[785 | 1086.90] loss=1.57 avg=1.47\n",
            "[786 | 1088.17] loss=1.41 avg=1.47\n",
            "[787 | 1089.45] loss=1.33 avg=1.47\n",
            "[788 | 1090.72] loss=1.49 avg=1.47\n",
            "[789 | 1091.99] loss=1.39 avg=1.47\n",
            "[790 | 1093.27] loss=1.46 avg=1.47\n",
            "[791 | 1094.54] loss=1.55 avg=1.47\n",
            "[792 | 1095.82] loss=1.73 avg=1.47\n",
            "[793 | 1097.09] loss=1.42 avg=1.47\n",
            "[794 | 1098.37] loss=1.46 avg=1.47\n",
            "[795 | 1099.64] loss=1.19 avg=1.47\n",
            "[796 | 1100.92] loss=1.46 avg=1.47\n",
            "[797 | 1102.19] loss=1.68 avg=1.47\n",
            "[798 | 1103.47] loss=1.45 avg=1.47\n",
            "[799 | 1104.74] loss=1.66 avg=1.47\n",
            "[800 | 1106.02] loss=1.51 avg=1.47\n",
            "======== SAMPLE 1 ========\n",
            ". 6 ounces) grated Parmesan\n",
            "📝Instructions: \n",
            "In large bowl, combine tomatoes, oil, wine, olive oil, garlic, Parmesan, and remaining tablespoon garlic. Slowly whisk in egg yolk. Whisk in chile-lime soda. Season with salt and pepper. Bring a very small saucepan of salted water to a boil, add garlic, garlic powder, and stir-fry flavors until garlic is golden.\n",
            "Serve over pizza crust, tops of crust, or as base for other kinds of pizzas.\n",
            "*Can be made 4 weeks ahead. Keep refrigerated; store in room temperature and refrigerate. <|endoftext|>\n",
            "whole milk small onion white sugar fresh lemon juice extra-virgin olive oil salt\n",
            "\n",
            "🥕Ingredients: \n",
            " 1/2 cup whole milk \n",
            " 1 small onion, sliced \n",
            " 1 tablespoon white sugar (from the kosher salt) \n",
            " 1/2 cup fresh lemon juice \n",
            " 2 tablespoons extra-virgin olive oil \n",
            " 1/2 teaspoon salt\n",
            "📝Instructions: \n",
            "Combine milk and onion in heavy large food processor. Add sugar, and puree until smooth. Transfer mixture to plates. Divide among bowls and top with cheese mixture.\n",
            "Combine milk and onion in heavy large food processor. Add sugar, and puree until smooth.\n",
            "Combine milk and onion in heavy large food processor. Add sugar, and puree until smooth.\n",
            "Dump 1/2 cup into a blender and puree into a large bowl. Add fresh butter, salt, and butter-flavored yogurt; blend to blend. Serve topped with a little mayonnaise.\n",
            "Combine milk and onion in heavy large food processor. Add sugar, and puree until smooth.\n",
            "Dump 1/2 cup into a blender and puree into a large bowl. Add fresh butter, salt, and butter-flavored yogurt; blend to blend. Serve topped with a little mayonnaise.\n",
            " <|endoftext|>\n",
            "water granulated garlic butter dry white wine sugar vanilla extract all-purpose flour\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 1/2 cups water \n",
            " 1/2 cup granulated garlic, minced \n",
            " 1/2 cup (2 sticks) butter, softened \n",
            " 1/4 cup (2 medium) dry white wine \n",
            " 3/4 cup (2 sticks) sugar, divided \n",
            " 1/4 teaspoon vanilla extract \n",
            " 3 3/4 cups all-purpose flour\n",
            "📝Instructions: \n",
            "In a large skillet warm water over low temperature, stirring occasionally, until almost boiling. In a large bowl whisk garlic, garlic powder, and white wine. Add sugar and vanilla extract and stir to combine. Add flour and stir just until combined. Cook butter in butter pot at low heat for 2 minutes or until very tender. Add wine and stir again, then stir in sugar and vanilla.\n",
            "In a large skillet warm water over low temperature, stirring occasionally, until almost boiling. In a large bowl whisk garlic, garlic powder, and white wine. Add sugar and vanilla extract and stir to combine. Add flour and stir just until combined. If sauce is too thick, spoon on sauce over butter.\n",
            "In a large skillet stir water and granulated garlic in pot around skillet until sauce is thick. Stir in wine, then stir into sauce. Cook pasta in melted butter over medium heat, stirring until sauce is heated through. Cook pasta in butter in hot skillet over low heat until pasta is opaque, a little bubbling around edges. Sprinkle with vanilla. Repeat with remaining sauce.\n",
            "In a large skillet, heat 2-inch-diameter metal grate over medium-high heat. Add pasta, and sprinkle with parsley and sea salt. Cook pasta until browned and just cooked through, stirring frequently. Transfer pasta to a plate.\n",
            "Add 2 cups water and granulated garlic to bowl with 1/2 cup flour. Fold in pasta mixture and knead in again until mixture resembles rice flour. Serve pasta over eggplant or white bread for dipping. Cover and refrigerate pasta.\n",
            "In a large skillet warm water over low heat, stirring occasionally, until almost boiling. In a large bowl whisk garlic, garlic powder, and white wine. Add sugar and vanilla extract and stir just until combined.\n",
            "Cook butter in butter pot at low heat for 2 minutes or until very tender. Add wine and stir just until combined.\n",
            "Cook pasta in butter in pot around skillet until sauce is thick. Stir in wine, then stir into sauce. Cook pasta in butter in hot skillet over low heat until pasta is opaque, a little bubbling around edges. Sprinkle with vanilla. Repeat with remaining sauce.\n",
            "Stuff pasta and butter in bottom of serving bowl. Top with eggplant and white bread. Spoon sauce over pasta and serve. <|endoftext|>\n",
            "mixed berries sugar water small orange bittersweet chocolate chopped hazelnuts\n",
            "\n",
            "\n",
            "[801 | 1118.57] loss=1.51 avg=1.47\n",
            "[802 | 1119.85] loss=1.46 avg=1.47\n",
            "[803 | 1121.12] loss=1.35 avg=1.47\n",
            "[804 | 1122.40] loss=1.36 avg=1.47\n",
            "[805 | 1123.68] loss=1.27 avg=1.47\n",
            "[806 | 1124.95] loss=1.59 avg=1.47\n",
            "[807 | 1126.23] loss=1.29 avg=1.47\n",
            "[808 | 1127.50] loss=1.52 avg=1.47\n",
            "[809 | 1128.78] loss=1.70 avg=1.47\n",
            "[810 | 1130.05] loss=1.42 avg=1.47\n",
            "[811 | 1131.33] loss=1.62 avg=1.47\n",
            "[812 | 1132.60] loss=1.42 avg=1.47\n",
            "[813 | 1133.88] loss=1.51 avg=1.47\n",
            "[814 | 1135.15] loss=1.32 avg=1.47\n",
            "[815 | 1136.43] loss=1.40 avg=1.47\n",
            "[816 | 1137.70] loss=1.57 avg=1.47\n",
            "[817 | 1138.98] loss=1.57 avg=1.47\n",
            "[818 | 1140.25] loss=1.44 avg=1.47\n",
            "[819 | 1141.53] loss=1.38 avg=1.47\n",
            "[820 | 1142.80] loss=1.42 avg=1.47\n",
            "[821 | 1144.08] loss=1.41 avg=1.47\n",
            "[822 | 1145.35] loss=1.48 avg=1.47\n",
            "[823 | 1146.63] loss=1.59 avg=1.47\n",
            "[824 | 1147.90] loss=1.32 avg=1.47\n",
            "[825 | 1149.18] loss=1.25 avg=1.47\n",
            "[826 | 1150.45] loss=1.29 avg=1.47\n",
            "[827 | 1151.73] loss=1.57 avg=1.47\n",
            "[828 | 1153.00] loss=1.33 avg=1.47\n",
            "[829 | 1154.28] loss=1.79 avg=1.47\n",
            "[830 | 1155.55] loss=1.58 avg=1.47\n",
            "[831 | 1156.83] loss=1.26 avg=1.47\n",
            "[832 | 1158.10] loss=1.68 avg=1.47\n",
            "[833 | 1159.38] loss=1.56 avg=1.47\n",
            "[834 | 1160.65] loss=1.57 avg=1.47\n",
            "[835 | 1161.93] loss=1.55 avg=1.47\n",
            "[836 | 1163.20] loss=1.25 avg=1.47\n",
            "[837 | 1164.48] loss=1.36 avg=1.47\n",
            "[838 | 1165.75] loss=1.56 avg=1.47\n",
            "[839 | 1167.03] loss=1.51 avg=1.47\n",
            "[840 | 1168.30] loss=1.79 avg=1.47\n",
            "[841 | 1169.58] loss=1.42 avg=1.47\n",
            "[842 | 1170.86] loss=1.29 avg=1.47\n",
            "[843 | 1172.13] loss=1.40 avg=1.47\n",
            "[844 | 1173.41] loss=1.27 avg=1.47\n",
            "[845 | 1174.68] loss=1.47 avg=1.47\n",
            "[846 | 1175.96] loss=1.59 avg=1.47\n",
            "[847 | 1177.23] loss=1.35 avg=1.47\n",
            "[848 | 1178.51] loss=1.46 avg=1.47\n",
            "[849 | 1179.78] loss=1.33 avg=1.47\n",
            "[850 | 1181.06] loss=1.62 avg=1.47\n",
            "[851 | 1182.33] loss=1.45 avg=1.47\n",
            "[852 | 1183.61] loss=1.54 avg=1.47\n",
            "[853 | 1184.88] loss=1.59 avg=1.47\n",
            "[854 | 1186.16] loss=1.57 avg=1.47\n",
            "[855 | 1187.43] loss=1.45 avg=1.47\n",
            "[856 | 1188.71] loss=1.39 avg=1.47\n",
            "[857 | 1189.98] loss=1.51 avg=1.47\n",
            "[858 | 1191.26] loss=1.45 avg=1.47\n",
            "[859 | 1192.53] loss=1.77 avg=1.47\n",
            "[860 | 1193.81] loss=1.60 avg=1.48\n",
            "[861 | 1195.08] loss=1.75 avg=1.48\n",
            "[862 | 1196.36] loss=1.29 avg=1.48\n",
            "[863 | 1197.63] loss=1.42 avg=1.48\n",
            "[864 | 1198.91] loss=1.47 avg=1.48\n",
            "[865 | 1200.18] loss=1.44 avg=1.48\n",
            "[866 | 1201.46] loss=1.53 avg=1.48\n",
            "[867 | 1202.74] loss=1.68 avg=1.48\n",
            "[868 | 1204.01] loss=1.40 avg=1.48\n",
            "[869 | 1205.29] loss=1.39 avg=1.48\n",
            "[870 | 1206.57] loss=1.31 avg=1.47\n",
            "[871 | 1207.84] loss=1.28 avg=1.47\n",
            "[872 | 1209.12] loss=1.44 avg=1.47\n",
            "[873 | 1210.39] loss=1.51 avg=1.47\n",
            "[874 | 1211.67] loss=1.57 avg=1.47\n",
            "[875 | 1212.94] loss=1.48 avg=1.47\n",
            "[876 | 1214.22] loss=1.43 avg=1.47\n",
            "[877 | 1215.49] loss=1.62 avg=1.47\n",
            "[878 | 1216.77] loss=1.49 avg=1.47\n",
            "[879 | 1218.04] loss=1.48 avg=1.47\n",
            "[880 | 1219.32] loss=1.51 avg=1.48\n",
            "[881 | 1220.59] loss=1.28 avg=1.47\n",
            "[882 | 1221.87] loss=1.64 avg=1.47\n",
            "[883 | 1223.14] loss=1.97 avg=1.48\n",
            "[884 | 1224.42] loss=1.36 avg=1.48\n",
            "[885 | 1225.70] loss=1.46 avg=1.48\n",
            "[886 | 1226.98] loss=1.51 avg=1.48\n",
            "[887 | 1228.25] loss=1.46 avg=1.48\n",
            "[888 | 1229.53] loss=1.28 avg=1.48\n",
            "[889 | 1230.80] loss=1.45 avg=1.48\n",
            "[890 | 1232.08] loss=1.16 avg=1.47\n",
            "[891 | 1233.35] loss=1.51 avg=1.47\n",
            "[892 | 1234.63] loss=1.34 avg=1.47\n",
            "[893 | 1235.90] loss=1.49 avg=1.47\n",
            "[894 | 1237.18] loss=1.37 avg=1.47\n",
            "[895 | 1238.45] loss=1.43 avg=1.47\n",
            "[896 | 1239.73] loss=1.41 avg=1.47\n",
            "[897 | 1241.01] loss=1.47 avg=1.47\n",
            "[898 | 1242.28] loss=1.21 avg=1.47\n",
            "[899 | 1243.56] loss=1.46 avg=1.47\n",
            "[900 | 1244.84] loss=1.48 avg=1.47\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            " 3 cups milk \n",
            " 1 cup finely chopped fresh chopped onion \n",
            " 5 whole cloves \n",
            " 1 tablespoon lemon juice \n",
            " Salt and pepper\n",
            "📝Instructions: \n",
            "Using 2 large butter or margarine cups, cut the cheesecloth lengthwise in half and then in half again. If there are pockets of cheesecloth, press down firmly.\n",
            "Arrange the cheesecloth inside the loaf in a tight-fitting buttered bag. Make sure there are no pockets of cheesecloth inside. If there are pockets, squeeze the cheesecloth in tightly then in another tight fitting bag, then in a tightly sealed bag and seal, seal and seal for 1 to 2 hours or more.\n",
            "With your hands, loosen the cheesecloth and turn it out with your hands over itself. Remove the excess oil from the pan and add the mushrooms. Cook until they are softened and just begin to brown with any cooking juices. Transfer the mixture back to the bowl that is used for shaping the cheesecloth.\n",
            "Heat the oil in a pan over medium high heat and fry the eggs until golden brown and well-done. Add the bacon bits and the chopped onions and cook until just cooked through.\n",
            "Cut the cheesecloth into thirds, cut each piece into 16 equal pieces, and put 1 of the pieces on the other bottom of an 8x5-inch loaf pan. Add the milk to the pan and simmer for 3 to 5 minutes, or until the cheese and egg flavors have incorporated. Pour the mixture over the flour and allow it to cook over medium to medium. Cover with a lid and continue cooking for 15 minutes until fully cooked.\n",
            "Remove the cheesecloth and stir in the onion, cloves, lemon juice and salt and pepper. Cover and let rest about 5 minutes, the cheese will still be soft but a bit crumbley to the touch.\n",
            "Pour the hot oil into the pan with the cheesecloth and cook until the oil is just beginning to smell and has started to brown, about 5 minutes. Stir in the onions and garlic and let rest for 30 minutes.\n",
            "Sprinkle the garlic paste evenly over the top of each bread. Sprinkle with the lemon and cheese. Serve immediately.\n",
            "Photograph by Antonis Achilleos <|endoftext|>\n",
            "heavy cream chopped fresh basil grated Parmigiano-Reggiano diced onion dried oregano shredded cheddar unsalted butter red pepper flakes\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 cup heavy cream \n",
            " 3 tablespoons chopped fresh basil (about 2 1/2 teaspoons for each) \n",
            " 3 tablespoons grated Parmigiano-Reggiano \n",
            " 3/4 cup diced onion \n",
            " 1/4 teaspoon dried oregano \n",
            " 1 1/2 tablespoons shredded Cheddar \n",
            " 2 tablespoons unsalted butter, melted \n",
            " 1/4 cup red pepper flakes (preferably Italian)\n",
            "📝Instructions: \n",
            "Divide the cream and basil into 2 equal 6- to 8-quart casserole dishes and preheat the oven to 400 degrees F. In a small bowl, stir together the remaining 1/2 teaspoon of cream, the Parmigiano-Reggiano, the onions, and the oregano until smooth. Mix in the Cheddar, 1/8 cup of the melted butter, and the melted 1/4 teaspoon of Parmigiano-Reggiano.\n",
            "Divide the half of the filling in half and then spread the center of the half onto the bottom of the casserole dishes. Top with a half of the remaining filling. Spoon the remainder of the filling over the top and top with the remaining half of the filling. Bake for 10 to 15 minutes or until a wooden spoon comes out clean. Serve hot. <|endoftext|>\n",
            "dry spaghetti or lentil lasagna fresh mozzarella cheese sour cream extra-virgin olive oil Kosher salt and freshly cracked black pepper slices Cheddar Italian bread\n",
            "\n",
            "🥕Ingredients: \n",
            " 4 cups dry spaghetti or lentil lasagna \n",
            " 3 cups fresh mozzarella cheese \n",
            " 1/2 cup sour cream \n",
            " 2 tablespoons extra-virgin olive oil \n",
            " Kosher salt and freshly cracked black pepper \n",
            " 8 slices Cheddar (about 2 ounces) \n",
            " 10 to 12 ounces Italian bread, cut into 6 slices\n",
            "📝Instructions: \n",
            "Preheat a grill pan over medium-high heat. Sprinkle the lasagna over the hot surface. Brush the outside of the lasagna with the melted melted cheese. Grill for 2 minutes on each side, turning occasionally until lightly cooked. Sprinkle the remaining cheese cheese over the center of the lasagna. Roast for 15 minutes. (After the chicken mixture is thoroughly cooked; your hands will be able to cook it longer).\n",
            "Place the sauce on a baking sheet and roast uncovered for 1 hour. Let cool slightly.\n",
            "Preheat an outdoor grill to medium-high heat. Roast the chicken in batches for 10 minutes and remove meat\n",
            "\n",
            "[901 | 1257.68] loss=1.72 avg=1.47\n",
            "[902 | 1258.96] loss=1.54 avg=1.47\n",
            "[903 | 1260.23] loss=1.47 avg=1.47\n",
            "[904 | 1261.51] loss=1.22 avg=1.47\n",
            "[905 | 1262.79] loss=1.37 avg=1.47\n",
            "[906 | 1264.06] loss=1.21 avg=1.46\n",
            "[907 | 1265.34] loss=1.54 avg=1.47\n",
            "[908 | 1266.61] loss=1.36 avg=1.46\n",
            "[909 | 1267.89] loss=1.38 avg=1.46\n",
            "[910 | 1269.17] loss=1.39 avg=1.46\n",
            "[911 | 1270.44] loss=1.30 avg=1.46\n",
            "[912 | 1271.71] loss=1.36 avg=1.46\n",
            "[913 | 1272.99] loss=1.56 avg=1.46\n",
            "[914 | 1274.27] loss=1.56 avg=1.46\n",
            "[915 | 1275.54] loss=1.47 avg=1.46\n",
            "[916 | 1276.82] loss=1.45 avg=1.46\n",
            "[917 | 1278.09] loss=1.55 avg=1.46\n",
            "[918 | 1279.37] loss=1.37 avg=1.46\n",
            "[919 | 1280.64] loss=1.56 avg=1.46\n",
            "[920 | 1281.92] loss=1.28 avg=1.46\n",
            "[921 | 1283.19] loss=1.33 avg=1.46\n",
            "[922 | 1284.47] loss=1.40 avg=1.46\n",
            "[923 | 1285.74] loss=1.71 avg=1.46\n",
            "[924 | 1287.02] loss=1.43 avg=1.46\n",
            "[925 | 1288.29] loss=1.35 avg=1.46\n",
            "[926 | 1289.57] loss=1.33 avg=1.46\n",
            "[927 | 1290.85] loss=1.21 avg=1.46\n",
            "[928 | 1292.12] loss=1.49 avg=1.46\n",
            "[929 | 1293.39] loss=1.52 avg=1.46\n",
            "[930 | 1294.67] loss=1.37 avg=1.46\n",
            "[931 | 1295.95] loss=1.20 avg=1.45\n",
            "[932 | 1297.22] loss=1.34 avg=1.45\n",
            "[933 | 1298.50] loss=1.70 avg=1.46\n",
            "[934 | 1299.77] loss=1.43 avg=1.46\n",
            "[935 | 1301.05] loss=1.32 avg=1.45\n",
            "[936 | 1302.32] loss=1.68 avg=1.46\n",
            "[937 | 1303.60] loss=1.63 avg=1.46\n",
            "[938 | 1304.87] loss=1.37 avg=1.46\n",
            "[939 | 1306.15] loss=1.57 avg=1.46\n",
            "[940 | 1307.42] loss=1.33 avg=1.46\n",
            "[941 | 1308.70] loss=1.29 avg=1.46\n",
            "[942 | 1309.97] loss=1.22 avg=1.45\n",
            "[943 | 1311.25] loss=1.49 avg=1.45\n",
            "[944 | 1312.52] loss=1.35 avg=1.45\n",
            "[945 | 1313.80] loss=1.32 avg=1.45\n",
            "[946 | 1315.07] loss=1.44 avg=1.45\n",
            "[947 | 1316.35] loss=1.27 avg=1.45\n",
            "[948 | 1317.62] loss=1.45 avg=1.45\n",
            "[949 | 1318.90] loss=1.35 avg=1.45\n",
            "[950 | 1320.17] loss=1.64 avg=1.45\n",
            "[951 | 1321.45] loss=1.49 avg=1.45\n",
            "[952 | 1322.72] loss=1.45 avg=1.45\n",
            "[953 | 1324.00] loss=1.38 avg=1.45\n",
            "[954 | 1325.27] loss=1.29 avg=1.45\n",
            "[955 | 1326.55] loss=1.30 avg=1.45\n",
            "[956 | 1327.82] loss=1.42 avg=1.45\n",
            "[957 | 1329.10] loss=1.35 avg=1.45\n",
            "[958 | 1330.37] loss=1.52 avg=1.45\n",
            "[959 | 1331.65] loss=1.29 avg=1.44\n",
            "[960 | 1332.92] loss=1.61 avg=1.45\n",
            "[961 | 1334.20] loss=1.25 avg=1.44\n",
            "[962 | 1335.47] loss=1.57 avg=1.45\n",
            "[963 | 1336.75] loss=1.44 avg=1.45\n",
            "[964 | 1338.03] loss=1.40 avg=1.44\n",
            "[965 | 1339.30] loss=1.43 avg=1.44\n",
            "[966 | 1340.57] loss=1.60 avg=1.45\n",
            "[967 | 1341.85] loss=1.36 avg=1.45\n",
            "[968 | 1343.13] loss=1.48 avg=1.45\n",
            "[969 | 1344.40] loss=1.47 avg=1.45\n",
            "[970 | 1345.68] loss=1.47 avg=1.45\n",
            "[971 | 1346.95] loss=1.67 avg=1.45\n",
            "[972 | 1348.23] loss=1.28 avg=1.45\n",
            "[973 | 1349.50] loss=1.52 avg=1.45\n",
            "[974 | 1350.78] loss=1.20 avg=1.45\n",
            "[975 | 1352.05] loss=1.15 avg=1.44\n",
            "[976 | 1353.33] loss=1.40 avg=1.44\n",
            "[977 | 1354.60] loss=1.25 avg=1.44\n",
            "[978 | 1355.88] loss=1.30 avg=1.44\n",
            "[979 | 1357.16] loss=1.43 avg=1.44\n",
            "[980 | 1358.43] loss=1.31 avg=1.44\n",
            "[981 | 1359.70] loss=1.52 avg=1.44\n",
            "[982 | 1360.98] loss=1.32 avg=1.44\n",
            "[983 | 1362.26] loss=1.47 avg=1.44\n",
            "[984 | 1363.53] loss=1.45 avg=1.44\n",
            "[985 | 1364.81] loss=1.52 avg=1.44\n",
            "[986 | 1366.08] loss=1.38 avg=1.44\n",
            "[987 | 1367.36] loss=1.39 avg=1.44\n",
            "[988 | 1368.63] loss=1.35 avg=1.44\n",
            "[989 | 1369.90] loss=1.53 avg=1.44\n",
            "[990 | 1371.18] loss=1.24 avg=1.44\n",
            "[991 | 1372.46] loss=1.54 avg=1.44\n",
            "[992 | 1373.73] loss=1.21 avg=1.43\n",
            "[993 | 1375.00] loss=1.35 avg=1.43\n",
            "[994 | 1376.28] loss=1.46 avg=1.43\n",
            "[995 | 1377.56] loss=1.36 avg=1.43\n",
            "[996 | 1378.83] loss=1.52 avg=1.43\n",
            "[997 | 1380.10] loss=1.60 avg=1.43\n",
            "[998 | 1381.38] loss=1.35 avg=1.43\n",
            "[999 | 1382.66] loss=1.46 avg=1.43\n",
            "[1000 | 1383.93] loss=1.23 avg=1.43\n",
            "Saving checkpoint/run1/model-1000\n",
            " \n",
            " 1 1/2 teaspoons ground cinnamon  \n",
            " 4 cups packed light brown sugar  \n",
            " 1 1/2 cups pure maple syrup  \n",
            " 1/2 cup heavy cream  \n",
            " \n",
            "📝Instructions: \n",
            "Whisk butter, sugar, and cinnamon together in a large bowl until smooth. Add brown sugar, maple syrup, cream of tartar, and butter mixture; beat until smooth.\n",
            "Beat in heavy cream.\n",
            " <|endoftext|>\n",
            "butter white sugar button mushrooms white sugar cornstarch pie spice unsalted butter butter\n",
            "\n",
            "🥕Ingredients: \n",
            " 1/2 cup butter  \n",
            " 2/3 cup white sugar  \n",
            " 1/2 pound button mushrooms, sliced  \n",
            " 1/2 cup white sugar  \n",
            " 1 tablespoon cornstarch  \n",
            " 1 tablespoon pie spice  \n",
            " 1 tablespoon unsalted butter, softened  \n",
            " \n",
            "📝Instructions: \n",
            "Preheat oven to 375 degrees F (190 degrees C).\n",
            "Melt butter in a large stockpot over medium heat. Add mushrooms; cook and stir until tender, about 5 minutes. Drain and rinse under cold water.\n",
            "Drain mushrooms and put them in a bowl. Add the sugar, eggs, and butter. Beat until smooth. Fold in the mushrooms and mushrooms. Spoon onto a baking sheet.\n",
            "Bake in the preheated oven until set, about 20 minutes.\n",
            " <|endoftext|>\n",
            "slices bacon slices bacon slices all-purpose flour milk salt and pepper to taste sliced green onions\n",
            "\n",
            "🥕Ingredients: \n",
            " 2 slices bacon  \n",
            " 8 slices bacon  \n",
            " 8 slices all-purpose flour  \n",
            " 1 cup milk  \n",
            " salt and pepper to taste  \n",
            " 2 cups sliced green onions  \n",
            " \n",
            "📝Instructions: \n",
            "Preheat oven to 350 degrees F (175 degrees C).\n",
            "Dip sliced bacon around the edges of the slices. Place slices on a cutting board.\n",
            "Place slices on a baking sheet.\n",
            "Bake in the preheated oven until bacon is browned and crisp, about 15 minutes.\n",
            " <|endoftext|>\n",
            "white sugar ground cinnamon salt and pepper to taste all-purpose flour butter cloves garlic chopped fresh dill chopped fresh thyme to taste grated orange zest\n",
            "\n",
            "🥕Ingredients: \n",
            " 3/4 cup white sugar  \n",
            " 1 tablespoon ground cinnamon  \n",
            " salt and pepper to taste  \n",
            " 2 3/4 cups all-purpose flour  \n",
            " 1 tablespoon butter  \n",
            " 6 cloves garlic, minced  \n",
            " 1/2 cup chopped fresh dill  \n",
            " 1/2 cup chopped fresh thyme to taste  \n",
            " 1/2 cup grated orange zest  \n",
            " \n",
            "📝Instructions: \n",
            "Preheat oven to 350 degrees F (175 degrees C).\n",
            "Whisk together the white sugar, ground cinnamon, salt and pepper.\n",
            "To make the topping: In a medium mixing bowl, mix the flour and butter.\n",
            "In a large bowl, mix the garlic, dill, thyme and zest.\n",
            "Place into the flour mixture and stir well to combine.\n",
            "Place the topping into the flour mixture and stir to combine.\n",
            "Place the topping into the prepared baking sheet and bake in the preheated oven until golden brown, about 10 minutes.\n",
            " <|endoftext|>\n",
            "fresh pineapple juice can condensed cream of mushroom soup can frozen corn frozen corn meal package frozen chopped spinach package frozen chopped spinach chopped fresh parsley dried parsley ground black pepper\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 cup fresh pineapple juice  \n",
            " 1 (12 ounce) can condensed cream of mushroom soup  \n",
            " 1 (12 ounce) can frozen corn (optional)  \n",
            " 1 cup frozen corn meal  \n",
            " 1 (16 ounce) package frozen chopped spinach  \n",
            " 1/4 cup frozen chopped spinach  \n",
            " 1/4 cup chopped fresh parsley  \n",
            " 1/4 teaspoon dried parsley  \n",
            " 1/4 teaspoon ground black pepper  \n",
            " \n",
            "📝Instructions: \n",
            "In a large saucepan over medium heat, bring the pineapple juice, soup, frozen corn meal, spinach, parsley, parsley, black pepper and ground pepper to a boil.\n",
            "Stir the mixture into the soup, and top with a scoop of half of the pineapple juice.\n",
            " <|endoftext|>\n",
            "lean ground beef red onion green bell pepper water cloves garlic ground cumin ground coriander ground black pepper\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 pound lean ground beef  \n",
            " 1 red onion, chopped  \n",
            " 1 green bell pepper, chopped  \n",
            " 1/2 cup water  \n",
            " 2 cloves garlic, minced  \n",
            " 1/2 teaspoon ground cumin  \n",
            " 1/2 teaspoon ground coriander \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt2.generate(\n",
        "    sess, \n",
        "    return_as_list=True, \n",
        "    prefix=\"chicken butter olive oil\"\n",
        "    )[0]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQh2msD9RY6n",
        "outputId": "62b3e665-9176-4869-a5aa-22ffbf53384d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chicken butter olive oil skinless lamb chops Kosher salt and freshly ground black pepper packages sauerkraut, drained and rinsed\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 pound chicken, cut into 1/2-inch pieces \n",
            " 1/2 cup sauerkraut (or 1/2 pound baby lean beef) \n",
            " 2 cups (about) white onion, chopped \n",
            " 1/2 bunch garlic, chopped \n",
            " 3/4 cup fresh Italian parsley leaves plus 1/4 cup for garnish \n",
            " 3 cloves garlic, minced \n",
            " 1 tablespoon minced fresh parsley leaves \n",
            " 3/4 cup white wine vinegar \n",
            " 2-inch casserole dish (about 16-ounces) \n",
            " Salt and freshly ground black pepper, to taste \n",
            " 5 ounces (about) fresh ground black pepper flakes \n",
            " 2 tablespoons (packed) Monterey Jack cheese\n",
            "📝Instructions: \n",
            "In a large pot, coat chicken with salt and pepper. Add sauerkraut and sauerkraut and sauerkraut; cover with cheese. Bring to a boil, reduce by half and simmer 5 minutes.\n",
            "In a large bowl, toss together onion, garlic, parsley and wine vinegar. Season with salt and pepper.\n",
            "In a Dutch oven or a large saucepan, melt the cheese. Add the casserole dish.\n",
            "In a medium skillet, heat the remaining 2 tablespoons of cheese and saute the chicken until it is browned, about 5 minutes. Add the sauerkraut and sauerkraut to the skillet and cook until the chicken is browned, 1 to 2 minutes. Sprinkle with salt and pepper. Serve with the cheese. <|endoftext|>\n",
            "kosher salt freshly ground black pepper freshly ground black pepper cloves garlic butter all-purpose flour large eggs freshly ground black pepper large eggs freshly ground black pepper milk large egg yolks salt and ground black pepper milk onions fresh parsley leaves\n",
            "\n",
            "🥕Ingredients: \n",
            " 2 teaspoons kosher salt \n",
            " 1 teaspoon freshly ground black pepper \n",
            " 1/2 teaspoon freshly ground black pepper \n",
            " 4 cloves garlic, chopped \n",
            " 8 ounces (about 8 ounces) butter \n",
            " 8 ounces all-purpose flour \n",
            " 3 large eggs \n",
            " 1/4 teaspoon freshly ground black pepper \n",
            " 4 large eggs, separated \n",
            " 1/4 teaspoon freshly ground black pepper \n",
            " 1/2 cup milk \n",
            " 3 large egg yolks \n",
            " salt and ground black pepper \n",
            " 1/2 cup milk \n",
            " 4 large egg yolks \n",
            " salt and black pepper \n",
            " 2 cups milk \n",
            " 4 large egg noodles\n",
            "📝Instructions: \n",
            "Meanwhile, make the filling.\n",
            "Put the butter, flour, eggs, and pepper in a food processor and pulse until crumbly. Add the milk, eggs, and pepper, and pulse until smooth.\n",
            "When the milk is smooth, turn the machine on and press it down on the side to release the milk, about 1 minute.\n",
            "Continue to add the milk until the milk is smooth and creamy.\n",
            "Turn the machine on and smooth the batter.\n",
            "Place the noodles in the hot sauce and melt in the hot sauce. <|endoftext|>\n",
            "fresh tomato paste sugar salt pepper fresh thyme leaves sugar\n",
            "\n",
            "🥕Ingredients: \n",
            " 1/2 cup fresh tomato paste \n",
            " 1/2 cup sugar \n",
            " 1 teaspoon salt \n",
            " 1/2 teaspoon pepper \n",
            " 1/4 cup fresh thyme leaves \n",
            " 3 teaspoons sugar\n",
            "📝Instructions: \n",
            "Heat the tomato paste in a saucepan over medium heat. Add the sugar, pinch of salt, and pepper, and stir until the sugar is dissolved.\n",
            "Serve the sauce on a platter. <|endoftext|>\n",
            "fresh strawberries white chocolate milk chocolate chips\n",
            "\n",
            "🥕Ingredients: \n",
            " 2 cups fresh strawberries \n",
            " 1 cup white chocolate milk chocolate chips\n",
            "📝Instructions: \n",
            "Preheat oven to 425 degrees F.\n",
            "In a small bowl, mix together the strawberries, chocolate milk and chocolate chips.\n",
            "Mix the remaining ingredients in the bowl and mix well.\n",
            "Yield: about 1 1/2 cups. <|endoftext|>\n",
            "chicken stock whole milk butter Salt and pepper to taste brown sugar kosher salt Squabble egg yolks\n",
            "\n",
            "🥕Ingredients: \n",
            " 1 1/2 cups chicken stock \n",
            " 1/2 cup whole milk \n",
            " 2 tablespoons butter \n",
            " Salt and pepper to taste \n",
            " 1 cup brown sugar \n",
            " 1/2 teaspoon kosher salt \n",
            " Squabble egg yolks\n",
            "📝Instructions: \n",
            "Preheat oven to 450 degrees F.\n",
            "In a large saucepan over medium heat, combine the chicken stock, milk, butter, and salt. Stir in the brown sugar, and the salt and pepper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7jDy54h6gnW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}